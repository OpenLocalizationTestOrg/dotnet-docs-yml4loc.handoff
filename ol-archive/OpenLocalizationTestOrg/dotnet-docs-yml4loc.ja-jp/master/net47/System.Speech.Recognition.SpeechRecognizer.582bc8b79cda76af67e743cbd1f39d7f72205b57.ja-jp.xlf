<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ja-jp">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-fdd610b" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">11cdbc5b7c62ef66a11c73ad4f8d52cc28cf3045</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">System.Speech.Recognition.SpeechRecognizer.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">net47</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c7681c4e34c1d332a7126c1cc03350933ee74939</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">07745e4752f5c5793ad98a238397a2dff147f1c4</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Provides access to the shared speech recognition service available on the Windows desktop.</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the shared recognizer to access Windows Speech Recognition.</source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object to add to the Windows speech user experience.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>This class provides control over various aspects of the speech recognition process:</source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>To manage speech recognition grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about current speech recognition operations, subscribe to the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>â€™s <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>To view or modify the number of alternate results the recognizer returns, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer returns recognition results in a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>To access or monitor the state of the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> properties and the <ph id="ph8">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevelUpdated&gt;</ph>, <ph id="ph9">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioSignalProblemOccurred&gt;</ph>, <ph id="ph10">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioStateChanged&gt;</ph>, and <ph id="ph11">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>To synchronize changes to the recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer uses more than one thread to perform tasks.</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>To emulate input to the shared recognizer, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>The configuration of Windows Speech Recognition is managed by the use of the <bpt id="p1">**</bpt>Speech Properties<ept id="p1">**</ept> dialog in the <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>This interface is used to select the default desktop speech recognition engine and language, the audio input device, and the sleep behavior of speech recognition.</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the configuration of Windows Speech Recognition is changed while the application is running, (for instance, if speech recognition is disabled or the input language is changed), the change affects all <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> objects.</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create an in-process speech recognizer that is independent of Windows Speech Recognition, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class.</source>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Always call <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Dispose%2A&gt;</ph> before you release your last reference to the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>Otherwise, the resources it is using will not be freed until the garbage collector calls the recognizer object's <ph id="ph1">`Finalize`</ph> method.</source>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>Initializes a new instance of the <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> class.</source>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object maintains a separate set of speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Gets the format of the audio being received by the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>The audio input format for the speech recognizer, or <ph id="ph1">`null`</ph> if the input to the recognizer is not configured.</source>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>Gets the level of the audio being received by the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>The audio level of the input to the speech recognizer, from 0 through 100.</source>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>Occurs when the shared recognizer reports the level of its audio input.</source>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises this event multiple times per second.</source>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>The frequency with which the event is raised depends on the computer on which the application is running.</source>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio level at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs.AudioLevel%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioLevelUpdatedEventArgs&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio level of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioLevel%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for an <ph id="ph1">`AudioLevelUpdated`</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>Gets the current location in the audio stream being generated by the device that is providing input to the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer receives input while the desktop speech recognition is running.</source>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioPosition`</ph> property references the input device's position in its generated audio stream.</source>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position in processing audio input.</source>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>The current location in the speech recognizer's audio input stream through which it has received input.</source>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer encounters a problem in the audio signal.</source>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get which problem occurred, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs.AudioSignalProblem%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioSignalProblemOccurredEventArgs&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for an <ph id="ph1">`AudioSignalProblemOccurred`</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Gets the state of the audio being received by the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>The state of the audio input to the speech recognizer.</source>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>Occurs when the state changes in the audio being received by the recognizer.</source>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the audio state at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs.AudioState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.AudioStateChangedEventArgs&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current audio state of the input to the recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioState%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about audio state, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.AudioState&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for an <ph id="ph1">`AudioStateChanged`</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>Disposes the <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> object and releases resources used during the session.</source>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`true`</ph> to release both managed and unmanaged resources; <ph id="ph2">`false`</ph> to release only unmanaged resources.</source>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>Disposes the <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition.</source>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <ph id="ph1">`null`</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <ph id="ph1">`null`</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for synchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>The recognition result for the recognition operation, or <ph id="ph1">`null`</ph>, if the operation is not successful or Windows Speech Recognition is in the <bpt id="p1">**</bpt>Sleeping<ept id="p1">**</ept> state.</source>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition.</source>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case and character width when applying grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about this type of comparison, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration values <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> and <ph id="ph3">&lt;xref:System.Globalization.CompareOptions.IgnoreWidth&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treat punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>The input for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>Emulates input of specific words to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the words and the loaded speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve" extradata="MT">
          <source>This method creates a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object using the information provided in the <ph id="ph2">`wordUnits`</ph> parameter.</source>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>An array of word units that contains the input for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>Emulates input of a phrase to the shared speech recognizer, using text instead of audio for asynchronous speech recognition, and specifies how the recognizer handles Unicode comparison between the phrase and the loaded speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer uses the <ph id="ph1">`compareOptions`</ph> when it applies grammar rules to the input phrase.</source>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers that ship with Vista and Windows 7 ignore case if the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions.OrdinalIgnoreCase&gt;</ph> or <ph id="ph2">&lt;xref:System.Globalization.CompareOptions.IgnoreCase&gt;</ph> value is present.</source>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers always ignore the character width and never ignore the Kana type.</source>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizers also ignore new lines and extra white space and treats punctuation as literal input.</source>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about character width and Kana type, see the <ph id="ph1">&lt;xref:System.Globalization.CompareOptions&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="205" translate="yes" xml:space="preserve">
          <source>The input phrase for the recognition operation.</source>
        </trans-unit>
        <trans-unit id="206" translate="yes" xml:space="preserve">
          <source>A bitwise combination of the enumeration values that describe the type of comparison to use for the emulated recognition operation.</source>
        </trans-unit>
        <trans-unit id="207" translate="yes" xml:space="preserve">
          <source>Occurs when the shared recognizer finalizes an asynchronous recognition operation for emulated input.</source>
        </trans-unit>
        <trans-unit id="208" translate="yes" xml:space="preserve" extradata="MT">
          <source>Each <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> method begins an asynchronous recognition operation.</source>
        </trans-unit>
        <trans-unit id="209" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the <ph id="ph1">`EmulateRecognizeCompleted`</ph> event when it finalizes the asynchronous operation.</source>
        </trans-unit>
        <trans-unit id="210" translate="yes" xml:space="preserve" extradata="MT">
          <source>The asynchronous recognition operation can raise the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph>, <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph>, and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> events.</source>
        </trans-unit>
        <trans-unit id="211" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeCompleted&gt;</ph> event is the last such event that the recognizer raises for a given operation.</source>
        </trans-unit>
        <trans-unit id="212" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for an <ph id="ph1">`EmulateRecognizeCompleted`</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="213" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="214" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="215" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="216" translate="yes" xml:space="preserve">
          <source>Gets or sets a value that indicates whether this <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> object is ready to process speech.</source>
        </trans-unit>
        <trans-unit id="217" translate="yes" xml:space="preserve" extradata="MT">
          <source>Changes to this property do not affect other instances of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class.</source>
        </trans-unit>
        <trans-unit id="218" translate="yes" xml:space="preserve" extradata="MT">
          <source>By default, the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property is <ph id="ph2">`true`</ph> for a newly instantiated instance of <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="219" translate="yes" xml:space="preserve" extradata="MT">
          <source>While the recognizer is disabled, none of the recognizer's speech recognition grammars are available for recognition operations.</source>
        </trans-unit>
        <trans-unit id="220" translate="yes" xml:space="preserve" extradata="MT">
          <source>Setting the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="221" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`true`</ph> if this <ph id="ph2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> object is performing speech recognition; otherwise, <ph id="ph3">`false`</ph>.</source>
        </trans-unit>
        <trans-unit id="222" translate="yes" xml:space="preserve">
          <source>Gets a collection of the <ph id="ph1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;&lt;/xref&gt;</ph> objects that are loaded in this <ph id="ph2">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> instance.</source>
        </trans-unit>
        <trans-unit id="223" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property does not return any speech recognition grammars loaded by another application.</source>
        </trans-unit>
        <trans-unit id="224" translate="yes" xml:space="preserve">
          <source>A collection of the <ph id="ph1">&lt;xref href="System.Speech.Recognition.Grammar"&gt;&lt;/xref&gt;</ph> objects that the application loaded into the current instance of the shared recognizer.</source>
        </trans-unit>
        <trans-unit id="225" translate="yes" xml:space="preserve">
          <source>Loads a speech recognition grammar.</source>
        </trans-unit>
        <trans-unit id="226" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
        </trans-unit>
        <trans-unit id="227" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
        </trans-unit>
        <trans-unit id="228" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a speech recognition grammar asynchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="229" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
        </trans-unit>
        <trans-unit id="230" translate="yes" xml:space="preserve">
          <source>Asynchronously loads a speech recognition grammar.</source>
        </trans-unit>
        <trans-unit id="231" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer completes this asynchronous operation, it raises a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarCompleted&gt;</ph> event.</source>
        </trans-unit>
        <trans-unit id="232" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer throws an exception if the speech recognition grammar is already loaded, is being asynchronously loaded, or has failed to load into any recognizer.</source>
        </trans-unit>
        <trans-unit id="233" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
        </trans-unit>
        <trans-unit id="234" translate="yes" xml:space="preserve" extradata="MT">
          <source>To load a speech recognition grammar synchronously, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammar%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="235" translate="yes" xml:space="preserve">
          <source>The speech recognition grammar to load.</source>
        </trans-unit>
        <trans-unit id="236" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer finishes the asynchronous loading of a speech recognition grammar.</source>
        </trans-unit>
        <trans-unit id="237" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.LoadGrammarAsync%2A&gt;</ph> method initiates an asynchronous operation.</source>
        </trans-unit>
        <trans-unit id="238" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the <ph id="ph1">`LoadGrammarCompleted`</ph> event when it completes the operation.</source>
        </trans-unit>
        <trans-unit id="239" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object that the recognizer loaded, use the <ph id="ph2">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs.Grammar%2A&gt;</ph> property of the associated <ph id="ph3">&lt;xref:System.Speech.Recognition.LoadGrammarCompletedEventArgs&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="240" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects the recognizer has loaded, use the recognizer's <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Grammars%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="241" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">`LoadGrammarCompleted`</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="242" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="243" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="244" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="245" translate="yes" xml:space="preserve">
          <source>Gets or sets the maximum number of alternate recognition results that the shared recognizer returns for each recognition operation.</source>
        </trans-unit>
        <trans-unit id="246" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> class contains the collection of <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the input.</source>
        </trans-unit>
        <trans-unit id="247" translate="yes" xml:space="preserve" extradata="MT">
          <source>The default value for <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.MaxAlternates%2A&gt;</ph> is 10.</source>
        </trans-unit>
        <trans-unit id="248" translate="yes" xml:space="preserve">
          <source>The maximum number of alternate results that the speech recognizer returns for each recognition operation.</source>
        </trans-unit>
        <trans-unit id="249" translate="yes" xml:space="preserve">
          <source>Gets or sets a value that indicates whether the shared recognizer pauses recognition operations while an application is handling a <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;&lt;/xref&gt;</ph> event.</source>
        </trans-unit>
        <trans-unit id="250" translate="yes" xml:space="preserve" extradata="MT">
          <source>Set this property to <ph id="ph1">`true`</ph>, if within the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler your application needs to change the state of the speech recognition service or change the loaded or enabled speech recognition grammars before the speech recognition service processes more input.</source>
        </trans-unit>
        <trans-unit id="251" translate="yes" xml:space="preserve" extradata="MT">
          <source>Setting the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> property to <ph id="ph2">`true`</ph> causes each <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler in every application to block the Windows speech recognition service.</source>
        </trans-unit>
        <trans-unit id="252" translate="yes" xml:space="preserve" extradata="MT">
          <source>To synchronize the changes to the shared recognizer with your application state, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="253" translate="yes" xml:space="preserve" extradata="MT">
          <source>When <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.PauseRecognizerOnRecognition%2A&gt;</ph> is <ph id="ph2">`true`</ph>, during the execution of the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> handler the speech recognition service pauses and buffers new audio input as it arrives.</source>
        </trans-unit>
        <trans-unit id="254" translate="yes" xml:space="preserve" extradata="MT">
          <source>Once the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized&gt;</ph> event handler exits, the speech recognition service resumes recognition and starts processing information from its input buffer.</source>
        </trans-unit>
        <trans-unit id="255" translate="yes" xml:space="preserve" extradata="MT">
          <source>To enable or disable the speech recognition service, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="256" translate="yes" xml:space="preserve">
          <source><ph id="ph1">`true`</ph> if the shared recognizer waits to process input while any application is handling the <ph id="ph2">&lt;xref href="System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized"&gt;&lt;/xref&gt;</ph> event; otherwise, <ph id="ph3">`false`</ph>.</source>
        </trans-unit>
        <trans-unit id="257" translate="yes" xml:space="preserve">
          <source>Gets the current location of the recognizer in the audio input that it is processing.</source>
        </trans-unit>
        <trans-unit id="258" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`RecognizerAudioPosition`</ph> property references the recognizer's position in processing its audio input.</source>
        </trans-unit>
        <trans-unit id="259" translate="yes" xml:space="preserve" extradata="MT">
          <source>By contrast, the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property references the input device's position in its generated audio stream.</source>
        </trans-unit>
        <trans-unit id="260" translate="yes" xml:space="preserve" extradata="MT">
          <source>These positions can be different.</source>
        </trans-unit>
        <trans-unit id="261" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, if the recognizer has received input for which it has not yet generated a recognition result then the value of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> property is less than the value of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="262" translate="yes" xml:space="preserve">
          <source>The position of the recognizer in the audio input that it is processing.</source>
        </trans-unit>
        <trans-unit id="263" translate="yes" xml:space="preserve">
          <source>Gets information about the shared speech recognizer.</source>
        </trans-unit>
        <trans-unit id="264" translate="yes" xml:space="preserve" extradata="MT">
          <source>This property returns information about the speech recognizer in use by Windows Speech Recognition.</source>
        </trans-unit>
        <trans-unit id="265" translate="yes" xml:space="preserve">
          <source>Information about the shared speech recognizer.</source>
        </trans-unit>
        <trans-unit id="266" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer pauses to synchronize recognition and other operations.</source>
        </trans-unit>
        <trans-unit id="267" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause a running instance of <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> before modifying its <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
        </trans-unit>
        <trans-unit id="268" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, while the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> is paused, you can load, unload, enable, and disable <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
        </trans-unit>
        <trans-unit id="269" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> raises this event when it is ready to accept modifications.</source>
        </trans-unit>
        <trans-unit id="270" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="271" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="272" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="273" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="274" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state and provides an offset and a user token for the associated event.</source>
        </trans-unit>
        <trans-unit id="275" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer does not initiate the recognizer update request until the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> equals the current <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> plus the value of the <ph id="ph3">`audioPositionAheadToRaiseUpdate`</ph> parameter.</source>
        </trans-unit>
        <trans-unit id="276" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
        </trans-unit>
        <trans-unit id="277" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
        </trans-unit>
        <trans-unit id="278" translate="yes" xml:space="preserve">
          <source>The offset from the current <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer.AudioPosition"&gt;&lt;/xref&gt;</ph> to delay the request.</source>
        </trans-unit>
        <trans-unit id="279" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state and provides a user token for the associated event.</source>
        </trans-unit>
        <trans-unit id="280" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> contains the value of the <ph id="ph4">`userToken`</ph> parameter.</source>
        </trans-unit>
        <trans-unit id="281" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="282" translate="yes" xml:space="preserve">
          <source>User-defined information that contains information for the operation.</source>
        </trans-unit>
        <trans-unit id="283" translate="yes" xml:space="preserve">
          <source>Requests that the shared recognizer pause and update its state.</source>
        </trans-unit>
        <trans-unit id="284" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer generates the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerUpdateReached&gt;</ph> event, the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs.UserToken%2A&gt;</ph> property of the <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognizerUpdateReachedEventArgs&gt;</ph> is <ph id="ph4">`null`</ph>.</source>
        </trans-unit>
        <trans-unit id="285" translate="yes" xml:space="preserve" extradata="MT">
          <source>To provide a user token, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="286" translate="yes" xml:space="preserve" extradata="MT">
          <source>To specify an audio position offset, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="287" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer detects input that it can identify as speech.</source>
        </trans-unit>
        <trans-unit id="288" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer can raise this event in response to input.</source>
        </trans-unit>
        <trans-unit id="289" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs.AudioPosition%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechDetectedEventArgs&gt;</ph> object indicates location in the input stream where the recognizer detected speech.</source>
        </trans-unit>
        <trans-unit id="290" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information see the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.AudioPosition%2A&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RecognizerAudioPosition%2A&gt;</ph> properties and the <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A&gt;</ph> and <ph id="ph4">&lt;xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="291" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechDetected&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="292" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="293" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="294" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="295" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer has recognized a word or words that may be a component of multiple complete phrases in a grammar.</source>
        </trans-unit>
        <trans-unit id="296" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer can raise this event when the input is ambiguous.</source>
        </trans-unit>
        <trans-unit id="297" translate="yes" xml:space="preserve" extradata="MT">
          <source>For example, for a speech recognition grammar that supports recognition of either "new game please" or "new game", "new game please" is an unambiguous input, and "new game" is an ambiguous input.</source>
        </trans-unit>
        <trans-unit id="298" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="299" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="300" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="301" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="302" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer receives input that does not match any of the speech recognition grammars it has loaded.</source>
        </trans-unit>
        <trans-unit id="303" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer raises this event if it determines that input does not match with sufficient confidence any of the loaded speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="304" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the rejected <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="305" translate="yes" xml:space="preserve" extradata="MT">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
        </trans-unit>
        <trans-unit id="306" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
        </trans-unit>
        <trans-unit id="307" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="308" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="309" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="310" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="311" translate="yes" xml:space="preserve">
          <source>Occurs when the recognizer receives input that matches one of its speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="312" translate="yes" xml:space="preserve" extradata="MT">
          <source>The recognizer raises the <ph id="ph1">`SpeechRecognized`</ph> event if it determines with sufficient confidence that input matches one of the loaded and enabled speech recognition grammars.</source>
        </trans-unit>
        <trans-unit id="313" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognitionEventArgs.Result%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionRejectedEventArgs&gt;</ph> contains the accepted <ph id="ph3">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="314" translate="yes" xml:space="preserve" extradata="MT">
          <source>Confidence thresholds for the shared recognizer, managed by <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, are associated with a user profile and stored in the Windows registry.</source>
        </trans-unit>
        <trans-unit id="315" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications should not write changes to the registry for the properties of the shared recognizer.</source>
        </trans-unit>
        <trans-unit id="316" translate="yes" xml:space="preserve" extradata="MT">
          <source>When the recognizer receives input that matches a grammar, the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object can raise the <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event.</source>
        </trans-unit>
        <trans-unit id="317" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> object's <ph id="ph2">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event is raised prior to the speech recognizer's <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event.</source>
        </trans-unit>
        <trans-unit id="318" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="319" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="320" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="321" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="322" translate="yes" xml:space="preserve">
          <source>Gets the state of a <ph id="ph1">&lt;xref href="System.Speech.Recognition.SpeechRecognizer"&gt;&lt;/xref&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="323" translate="yes" xml:space="preserve" extradata="MT">
          <source>This read-only property indicates whether the shared recognizer resident in Windows is in the <ph id="ph1">`Stopped`</ph> or the <ph id="ph2">`Listening`</ph> state.</source>
        </trans-unit>
        <trans-unit id="324" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information, see the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> enumeration.</source>
        </trans-unit>
        <trans-unit id="325" translate="yes" xml:space="preserve">
          <source>The state of the <ph id="ph1">`SpeechRecognizer`</ph> object.</source>
        </trans-unit>
        <trans-unit id="326" translate="yes" xml:space="preserve">
          <source>Occurs when the running state of the Windows Desktop Speech Technology recognition engine changes.</source>
        </trans-unit>
        <trans-unit id="327" translate="yes" xml:space="preserve" extradata="MT">
          <source>The shared recognizer raises this event when the state of Windows Speech Recognition changes to the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState.Listening&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState.Stopped&gt;</ph> state.</source>
        </trans-unit>
        <trans-unit id="328" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the state of the shared recognizer at the time of the event, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the associated <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph>.</source>
        </trans-unit>
        <trans-unit id="329" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get the current state of the shared recognizer, use the recognizer's <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="330" translate="yes" xml:space="preserve" extradata="MT">
          <source>When you create a delegate for a <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> event, you identify the method that will handle the event.</source>
        </trans-unit>
        <trans-unit id="331" translate="yes" xml:space="preserve" extradata="MT">
          <source>To associate the event with your event handler, add an instance of the delegate to the event.</source>
        </trans-unit>
        <trans-unit id="332" translate="yes" xml:space="preserve" extradata="MT">
          <source>The event handler is called whenever the event occurs, unless you remove the delegate.</source>
        </trans-unit>
        <trans-unit id="333" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more information about event-handler delegates, see <bpt id="p1">[</bpt>Events and Delegates<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=162418)</ept>.</source>
        </trans-unit>
        <trans-unit id="334" translate="yes" xml:space="preserve">
          <source>Unloads all speech recognition grammars from the shared recognizer.</source>
        </trans-unit>
        <trans-unit id="335" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is currently loading a grammar asynchronously, this method waits until the grammar is loaded, before it unloads all of the recognizer's grammars.</source>
        </trans-unit>
        <trans-unit id="336" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload a specific grammar, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadGrammar%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="337" translate="yes" xml:space="preserve">
          <source>Unloads a specified speech recognition grammar from the shared recognizer.</source>
        </trans-unit>
        <trans-unit id="338" translate="yes" xml:space="preserve" extradata="MT">
          <source>If the recognizer is running, applications must use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.RequestRecognizerUpdate%2A&gt;</ph> to pause the speech recognition engine before loading, unloading,  enabling, or disabling a grammar.</source>
        </trans-unit>
        <trans-unit id="339" translate="yes" xml:space="preserve" extradata="MT">
          <source>To unload all grammars, use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.UnloadAllGrammars%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="340" translate="yes" xml:space="preserve">
          <source>The grammar to unload.</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>