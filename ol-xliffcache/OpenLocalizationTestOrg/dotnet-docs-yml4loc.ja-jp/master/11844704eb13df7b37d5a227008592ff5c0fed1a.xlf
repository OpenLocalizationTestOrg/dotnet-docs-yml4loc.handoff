<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ja-jp">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-fdd610b" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">11844704eb13df7b37d5a227008592ff5c0fed1a</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">System.Speech.Recognition.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">net47</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">0042ae533d6586d4cd0330033d27a95907f314dc</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">6f5492a4a14b0972023257b1504a10175620ca76</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <ph id="ph1">&lt;xref href="System.Speech.Recognition"&gt;&lt;/xref&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source>The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.</source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications use the <ph id="ph1">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Grammars<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using a constructor for the <ph id="ph1">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id="ph2">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>To create grammars programmatically that conform to the <bpt id="p1">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id="p1">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id="ph1">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id="ph1">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id="ph2">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.</source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>In addition, the <ph id="ph1">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Create Grammars<ept id="p1">](http://msdn.microsoft.com/en-us/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Manage Speech Recognition Engines<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>Instances of <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id="ph3">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id="p1">**</bpt>Control Panel<ept id="p1">**</ept>.</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>Such applications accept input through a computer's default audio input mechanism.</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>For more control over the configuration and type of recognition engine, build an application using <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.</source>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source>Using the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.</source>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id="p1">](http://msdn.microsoft.com/en-us/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.</source>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`AudioLevelUpdated`</ph>, <ph id="ph2">`AudioSignalProblemOccurred`</ph>, <ph id="ph3">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.</source>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.</source>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>The speech recognition engine raises the <ph id="ph1">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id="ph2">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.</source>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>Other types of events include the <ph id="ph1">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.</source>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.</source>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id="ph1">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.</source>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Recognition Events<ept id="p1">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>