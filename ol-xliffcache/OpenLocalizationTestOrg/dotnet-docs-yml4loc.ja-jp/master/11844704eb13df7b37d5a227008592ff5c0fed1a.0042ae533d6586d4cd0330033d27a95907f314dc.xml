{"nodes":[{"content":"The <xref href=\"System.Speech.Recognition\"></xref> namespace contains Windows Desktop Speech technology types for implementing speech recognition.","nodes":[{"pos":[0,146],"content":"The <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition\"&gt;&lt;/xref&gt;</ph> namespace contains Windows Desktop Speech technology types for implementing speech recognition.","source":"The <xref href=\"System.Speech.Recognition\"></xref> namespace contains Windows Desktop Speech technology types for implementing speech recognition."}],"pos":[2046,2193],"yaml":true},{"content":"The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.  \n  \n Applications use the <xref:System.Speech.Recognition> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.  \n  \n **Create Grammars**  \n  \n You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input. Using a constructor for the <xref:System.Speech.Recognition.Grammar> class, you can create a grammar object at runtime from <xref:System.Speech.Recognition.GrammarBuilder> or <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, or from a file, a string, or a stream that contains a definition of a grammar.  \n  \n Using the <xref:System.Speech.Recognition.GrammarBuilder> and <xref:System.Speech.Recognition.Choices> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios. To create grammars programmatically that conform to the [Speech Recognition Grammar Specification 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) and take advantage of the authoring flexibility of SRGS, use the types of the <xref:System.Speech.Recognition.SrgsGrammar> namespace. You can also create XML-format SRGS grammars using any text editor and use the result to create <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , or <xref:System.Speech.Recognition.Grammar> objects.  \n  \n In addition, the <xref:System.Speech.Recognition.DictationGrammar> class provides a special-case grammar to support a conventional dictation model.  \n  \n See [Create Grammars](http://msdn.microsoft.com/en-us/dbea278c-21a5-4816-aee7-5fd88ef993dd) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information and examples.  \n  \n **Manage Speech Recognition Engines**  \n  \n Instances of <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> supplied with <xref:System.Speech.Recognition.Grammar> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.  \n  \n You can use the <xref:System.Speech.Recognition.SpeechRecognizer> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the **Control Panel**. Such applications accept input through a computer's default audio input mechanism.  \n  \n For more control over the configuration and type of recognition engine, build an application using <xref:System.Speech.Recognition.SpeechRecognitionEngine>, which runs in-process. Using the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class, you can also dynamically select audio input from devices, files, or streams.  \n  \n See [Initialize and Manage a Speech Recognition Engine](http://msdn.microsoft.com/en-us/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information.  \n  \n **Respond to Events**  \n  \n <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> objects generate events in response to audio input to the speech recognition engine. The `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` events are raised in response to changes in the incoming signal. The `SpeechDetected` event is raised when the speech recognition engine identifies incoming audio as speech. The speech recognition engine raises the `SpeechRecognized` event when it matches speech input to one of its loaded grammars, and raises the `SpeechRecognitionRejected` when speech input does not match any of its loaded grammars.  \n  \n Other types of events include the `LoadGrammarCompleted` event which a speech recognition engine raises when it has loaded a grammar. The <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> is exclusive to the <xref:System.Speech.Recognition.SpeechRecognizer> class, which raises the event when the state of Windows Speech Recognition changes.  \n  \n You can register to be notified for events that the speech recognition engine raises and create handlers using the `EventsArgs` classes associated with each of these events to program your application's behavior when an event is raised.  \n  \n See [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information.","nodes":[{"pos":[0,187],"content":"The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.","nodes":[{"content":"The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.","pos":[0,187]}]},{"pos":[194,475],"content":"Applications use the <xref:System.Speech.Recognition> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.","nodes":[{"content":"Applications use the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition&gt;</ph> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.","pos":[0,281],"source":"Applications use the <xref:System.Speech.Recognition> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure."}]},{"pos":[482,501],"content":"<bpt id=\"p1\">**</bpt>Create Grammars<ept id=\"p1\">**</ept>","source":"**Create Grammars**"},{"pos":[508,985],"content":"You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input. Using a constructor for the <xref:System.Speech.Recognition.Grammar> class, you can create a grammar object at runtime from <xref:System.Speech.Recognition.GrammarBuilder> or <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, or from a file, a string, or a stream that contains a definition of a grammar.","nodes":[{"content":"You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input. Using a constructor for the <xref:System.Speech.Recognition.Grammar> class, you can create a grammar object at runtime from <xref:System.Speech.Recognition.GrammarBuilder> or <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, or from a file, a string, or a stream that contains a definition of a grammar.","pos":[0,477],"nodes":[{"content":"You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input.","pos":[0,154]},{"content":"Using a constructor for the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class, you can create a grammar object at runtime from <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> or <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> instances, or from a file, a string, or a stream that contains a definition of a grammar.","pos":[155,477],"source":" Using a constructor for the <xref:System.Speech.Recognition.Grammar> class, you can create a grammar object at runtime from <xref:System.Speech.Recognition.GrammarBuilder> or <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, or from a file, a string, or a stream that contains a definition of a grammar."}]}]},{"pos":[992,1788],"content":"Using the <xref:System.Speech.Recognition.GrammarBuilder> and <xref:System.Speech.Recognition.Choices> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios. To create grammars programmatically that conform to the [Speech Recognition Grammar Specification 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) and take advantage of the authoring flexibility of SRGS, use the types of the <xref:System.Speech.Recognition.SrgsGrammar> namespace. You can also create XML-format SRGS grammars using any text editor and use the result to create <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , or <xref:System.Speech.Recognition.Grammar> objects.","nodes":[{"content":"Using the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.Choices&gt;</ph> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios.","pos":[0,247],"source":"Using the <xref:System.Speech.Recognition.GrammarBuilder> and <xref:System.Speech.Recognition.Choices> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios."},{"content":"To create grammars programmatically that conform to the <bpt id=\"p1\">[</bpt>Speech Recognition Grammar Specification 1.0 (SRGS)<ept id=\"p1\">](http://go.microsoft.com/fwlink/?LinkId=201761)</ept> and take advantage of the authoring flexibility of SRGS, use the types of the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SrgsGrammar&gt;</ph> namespace.","pos":[248,538],"source":" To create grammars programmatically that conform to the [Speech Recognition Grammar Specification 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) and take advantage of the authoring flexibility of SRGS, use the types of the <xref:System.Speech.Recognition.SrgsGrammar> namespace."},{"content":"You can also create XML-format SRGS grammars using any text editor and use the result to create <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.GrammarBuilder&gt;</ph>, <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument&gt;</ph> , or <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects.","pos":[539,796],"source":" You can also create XML-format SRGS grammars using any text editor and use the result to create <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , or <xref:System.Speech.Recognition.Grammar> objects."}]},{"pos":[1795,1942],"content":"In addition, the <xref:System.Speech.Recognition.DictationGrammar> class provides a special-case grammar to support a conventional dictation model.","nodes":[{"content":"In addition, the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> class provides a special-case grammar to support a conventional dictation model.","pos":[0,147],"source":"In addition, the <xref:System.Speech.Recognition.DictationGrammar> class provides a special-case grammar to support a conventional dictation model."}]},{"pos":[1949,2209],"content":"See <bpt id=\"p1\">[</bpt>Create Grammars<ept id=\"p1\">](http://msdn.microsoft.com/en-us/dbea278c-21a5-4816-aee7-5fd88ef993dd)</ept> in the <bpt id=\"p2\">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id=\"p2\">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.","source":"See [Create Grammars](http://msdn.microsoft.com/en-us/dbea278c-21a5-4816-aee7-5fd88ef993dd) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information and examples."},{"pos":[2216,2253],"content":"<bpt id=\"p1\">**</bpt>Manage Speech Recognition Engines<ept id=\"p1\">**</ept>","source":"**Manage Speech Recognition Engines**"},{"pos":[2260,2549],"content":"Instances of <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> supplied with <xref:System.Speech.Recognition.Grammar> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.","nodes":[{"content":"Instances of <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> supplied with <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.","pos":[0,289],"source":"Instances of <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> supplied with <xref:System.Speech.Recognition.Grammar> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology."}]},{"pos":[2556,2859],"content":"You can use the <xref:System.Speech.Recognition.SpeechRecognizer> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the **Control Panel**. Such applications accept input through a computer's default audio input mechanism.","nodes":[{"content":"You can use the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the <bpt id=\"p1\">**</bpt>Control Panel<ept id=\"p1\">**</ept>.","pos":[0,220],"source":"You can use the <xref:System.Speech.Recognition.SpeechRecognizer> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the **Control Panel**."},{"content":"Such applications accept input through a computer's default audio input mechanism.","pos":[221,303]}]},{"pos":[2866,3196],"content":"For more control over the configuration and type of recognition engine, build an application using <xref:System.Speech.Recognition.SpeechRecognitionEngine>, which runs in-process. Using the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class, you can also dynamically select audio input from devices, files, or streams.","nodes":[{"content":"For more control over the configuration and type of recognition engine, build an application using <xref:System.Speech.Recognition.SpeechRecognitionEngine>, which runs in-process. Using the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class, you can also dynamically select audio input from devices, files, or streams.","pos":[0,330],"nodes":[{"content":"For more control over the configuration and type of recognition engine, build an application using <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, which runs in-process.","pos":[0,179],"source":"For more control over the configuration and type of recognition engine, build an application using <xref:System.Speech.Recognition.SpeechRecognitionEngine>, which runs in-process."},{"content":"Using the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class, you can also dynamically select audio input from devices, files, or streams.","pos":[180,330],"source":" Using the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class, you can also dynamically select audio input from devices, files, or streams."}]}]},{"pos":[3203,3484],"content":"See <bpt id=\"p1\">[</bpt>Initialize and Manage a Speech Recognition Engine<ept id=\"p1\">](http://msdn.microsoft.com/en-us/6eed5b59-1258-4013-8a4c-a1ddabd93ae4)</ept> in the <bpt id=\"p2\">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id=\"p2\">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.","source":"See [Initialize and Manage a Speech Recognition Engine](http://msdn.microsoft.com/en-us/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information."},{"pos":[3491,3512],"content":"<bpt id=\"p1\">**</bpt>Respond to Events<ept id=\"p1\">**</ept>","source":"**Respond to Events**"},{"pos":[3519,4193],"content":"<xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> objects generate events in response to audio input to the speech recognition engine. The `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` events are raised in response to changes in the incoming signal. The `SpeechDetected` event is raised when the speech recognition engine identifies incoming audio as speech. The speech recognition engine raises the `SpeechRecognized` event when it matches speech input to one of its loaded grammars, and raises the `SpeechRecognitionRejected` when speech input does not match any of its loaded grammars.","nodes":[{"content":"<ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> objects generate events in response to audio input to the speech recognition engine.","pos":[0,195],"source":"<xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> objects generate events in response to audio input to the speech recognition engine."},{"content":"The <ph id=\"ph1\">`AudioLevelUpdated`</ph>, <ph id=\"ph2\">`AudioSignalProblemOccurred`</ph>, <ph id=\"ph3\">`AudioStateChanged`</ph> events are raised in response to changes in the incoming signal.","pos":[196,335],"source":" The `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` events are raised in response to changes in the incoming signal."},{"content":"The <ph id=\"ph1\">`SpeechDetected`</ph> event is raised when the speech recognition engine identifies incoming audio as speech.","pos":[336,444],"source":" The `SpeechDetected` event is raised when the speech recognition engine identifies incoming audio as speech."},{"content":"The speech recognition engine raises the <ph id=\"ph1\">`SpeechRecognized`</ph> event when it matches speech input to one of its loaded grammars, and raises the <ph id=\"ph2\">`SpeechRecognitionRejected`</ph> when speech input does not match any of its loaded grammars.","pos":[445,674],"source":" The speech recognition engine raises the `SpeechRecognized` event when it matches speech input to one of its loaded grammars, and raises the `SpeechRecognitionRejected` when speech input does not match any of its loaded grammars."}]},{"pos":[4200,4554],"content":"Other types of events include the `LoadGrammarCompleted` event which a speech recognition engine raises when it has loaded a grammar. The <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> is exclusive to the <xref:System.Speech.Recognition.SpeechRecognizer> class, which raises the event when the state of Windows Speech Recognition changes.","nodes":[{"content":"Other types of events include the <ph id=\"ph1\">`LoadGrammarCompleted`</ph> event which a speech recognition engine raises when it has loaded a grammar.","pos":[0,133],"source":"Other types of events include the `LoadGrammarCompleted` event which a speech recognition engine raises when it has loaded a grammar."},{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> is exclusive to the <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class, which raises the event when the state of Windows Speech Recognition changes.","pos":[134,354],"source":" The <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> is exclusive to the <xref:System.Speech.Recognition.SpeechRecognizer> class, which raises the event when the state of Windows Speech Recognition changes."}]},{"pos":[4561,4797],"content":"You can register to be notified for events that the speech recognition engine raises and create handlers using the <ph id=\"ph1\">`EventsArgs`</ph> classes associated with each of these events to program your application's behavior when an event is raised.","source":"You can register to be notified for events that the speech recognition engine raises and create handlers using the `EventsArgs` classes associated with each of these events to program your application's behavior when an event is raised."},{"pos":[4804,5067],"content":"See <bpt id=\"p1\">[</bpt>Using Speech Recognition Events<ept id=\"p1\">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept> in the <bpt id=\"p2\">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id=\"p2\">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.","source":"See [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information."}],"pos":[2204,7306],"yaml":true,"extradata":"MT"}],"content":"### YamlMime:ManagedReference\nitems:\n- uid: System.Speech.Recognition\n  id: System.Speech.Recognition\n  children:\n  - System.Speech.Recognition.AudioLevelUpdatedEventArgs\n  - System.Speech.Recognition.AudioSignalProblem\n  - System.Speech.Recognition.AudioSignalProblemOccurredEventArgs\n  - System.Speech.Recognition.AudioState\n  - System.Speech.Recognition.AudioStateChangedEventArgs\n  - System.Speech.Recognition.Choices\n  - System.Speech.Recognition.DictationGrammar\n  - System.Speech.Recognition.DisplayAttributes\n  - System.Speech.Recognition.EmulateRecognizeCompletedEventArgs\n  - System.Speech.Recognition.Grammar\n  - System.Speech.Recognition.GrammarBuilder\n  - System.Speech.Recognition.LoadGrammarCompletedEventArgs\n  - System.Speech.Recognition.RecognitionEventArgs\n  - System.Speech.Recognition.RecognitionResult\n  - System.Speech.Recognition.RecognizeCompletedEventArgs\n  - System.Speech.Recognition.RecognizedAudio\n  - System.Speech.Recognition.RecognizedPhrase\n  - System.Speech.Recognition.RecognizedWordUnit\n  - System.Speech.Recognition.RecognizeMode\n  - System.Speech.Recognition.RecognizerInfo\n  - System.Speech.Recognition.RecognizerState\n  - System.Speech.Recognition.RecognizerUpdateReachedEventArgs\n  - System.Speech.Recognition.ReplacementText\n  - System.Speech.Recognition.SemanticResultKey\n  - System.Speech.Recognition.SemanticResultValue\n  - System.Speech.Recognition.SemanticValue\n  - System.Speech.Recognition.SpeechDetectedEventArgs\n  - System.Speech.Recognition.SpeechHypothesizedEventArgs\n  - System.Speech.Recognition.SpeechRecognitionEngine\n  - System.Speech.Recognition.SpeechRecognitionRejectedEventArgs\n  - System.Speech.Recognition.SpeechRecognizedEventArgs\n  - System.Speech.Recognition.SpeechRecognizer\n  - System.Speech.Recognition.SpeechUI\n  - System.Speech.Recognition.StateChangedEventArgs\n  - System.Speech.Recognition.SubsetMatchingMode\n  langs:\n  - csharp\n  name: System.Speech.Recognition\n  nameWithType: System.Speech.Recognition\n  fullName: System.Speech.Recognition\n  type: Namespace\n  summary: The <xref href=\"System.Speech.Recognition\"></xref> namespace contains Windows Desktop Speech technology types for implementing speech recognition.\n  remarks: \"The Windows Desktop Speech Technology software offers a basic speech recognition infrastructure that digitizes acoustical signals, and recovers words and speech elements from audio input.  \\n  \\n Applications use the <xref:System.Speech.Recognition> namespace to access and extend this basic speech recognition technology by defining algorithms for identifying and acting on specific phrases or word patterns, and by managing the runtime behavior of this speech infrastructure.  \\n  \\n **Create Grammars**  \\n  \\n You create grammars, which consist of a set of rules or constraints, to define words and phrases that your application will recognize as meaningful input. Using a constructor for the <xref:System.Speech.Recognition.Grammar> class, you can create a grammar object at runtime from <xref:System.Speech.Recognition.GrammarBuilder> or <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> instances, or from a file, a string, or a stream that contains a definition of a grammar.  \\n  \\n Using the <xref:System.Speech.Recognition.GrammarBuilder> and <xref:System.Speech.Recognition.Choices> classes, you can programmatically create grammars of low to medium complexity that can be used to perform recognition for many common scenarios. To create grammars programmatically that conform to the [Speech Recognition Grammar Specification 1.0 (SRGS)](http://go.microsoft.com/fwlink/?LinkId=201761) and take advantage of the authoring flexibility of SRGS, use the types of the <xref:System.Speech.Recognition.SrgsGrammar> namespace. You can also create XML-format SRGS grammars using any text editor and use the result to create <xref:System.Speech.Recognition.GrammarBuilder>, <xref:System.Speech.Recognition.SrgsGrammar.SrgsDocument> , or <xref:System.Speech.Recognition.Grammar> objects.  \\n  \\n In addition, the <xref:System.Speech.Recognition.DictationGrammar> class provides a special-case grammar to support a conventional dictation model.  \\n  \\n See [Create Grammars](http://msdn.microsoft.com/en-us/dbea278c-21a5-4816-aee7-5fd88ef993dd) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information and examples.  \\n  \\n **Manage Speech Recognition Engines**  \\n  \\n Instances of <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> supplied with <xref:System.Speech.Recognition.Grammar> objects provide the primary access to the speech recognition engines of the Windows Desktop Speech Technology.  \\n  \\n You can use the <xref:System.Speech.Recognition.SpeechRecognizer> class to create client applications that use the speech recognition technology provided by Windows, which you can configure through the **Control Panel**. Such applications accept input through a computer's default audio input mechanism.  \\n  \\n For more control over the configuration and type of recognition engine, build an application using <xref:System.Speech.Recognition.SpeechRecognitionEngine>, which runs in-process. Using the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class, you can also dynamically select audio input from devices, files, or streams.  \\n  \\n See [Initialize and Manage a Speech Recognition Engine](http://msdn.microsoft.com/en-us/6eed5b59-1258-4013-8a4c-a1ddabd93ae4) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information.  \\n  \\n **Respond to Events**  \\n  \\n <xref:System.Speech.Recognition.SpeechRecognizer> and <xref:System.Speech.Recognition.SpeechRecognitionEngine> objects generate events in response to audio input to the speech recognition engine. The `AudioLevelUpdated`, `AudioSignalProblemOccurred`, `AudioStateChanged` events are raised in response to changes in the incoming signal. The `SpeechDetected` event is raised when the speech recognition engine identifies incoming audio as speech. The speech recognition engine raises the `SpeechRecognized` event when it matches speech input to one of its loaded grammars, and raises the `SpeechRecognitionRejected` when speech input does not match any of its loaded grammars.  \\n  \\n Other types of events include the `LoadGrammarCompleted` event which a speech recognition engine raises when it has loaded a grammar. The <xref:System.Speech.Recognition.SpeechRecognizer.StateChanged> is exclusive to the <xref:System.Speech.Recognition.SpeechRecognizer> class, which raises the event when the state of Windows Speech Recognition changes.  \\n  \\n You can register to be notified for events that the speech recognition engine raises and create handlers using the `EventsArgs` classes associated with each of these events to program your application's behavior when an event is raised.  \\n  \\n See [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482) in the [System Speech Programming Guide for .NET Framework 4.0](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043) for more information.\"\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/ns-System.Speech.Recognition.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\nreferences:\n- uid: System.Speech.Recognition.AudioLevelUpdatedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: AudioLevelUpdatedEventArgs\n  nameWithType: AudioLevelUpdatedEventArgs\n  fullName: System.Speech.Recognition.AudioLevelUpdatedEventArgs\n- uid: System.Speech.Recognition.AudioSignalProblem\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: AudioSignalProblem\n  nameWithType: AudioSignalProblem\n  fullName: System.Speech.Recognition.AudioSignalProblem\n- uid: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: AudioSignalProblemOccurredEventArgs\n  nameWithType: AudioSignalProblemOccurredEventArgs\n  fullName: System.Speech.Recognition.AudioSignalProblemOccurredEventArgs\n- uid: System.Speech.Recognition.AudioState\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: AudioState\n  nameWithType: AudioState\n  fullName: System.Speech.Recognition.AudioState\n- uid: System.Speech.Recognition.AudioStateChangedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: AudioStateChangedEventArgs\n  nameWithType: AudioStateChangedEventArgs\n  fullName: System.Speech.Recognition.AudioStateChangedEventArgs\n- uid: System.Speech.Recognition.Choices\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: Choices\n  nameWithType: Choices\n  fullName: System.Speech.Recognition.Choices\n- uid: System.Speech.Recognition.DictationGrammar\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: DictationGrammar\n  nameWithType: DictationGrammar\n  fullName: System.Speech.Recognition.DictationGrammar\n- uid: System.Speech.Recognition.DisplayAttributes\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: DisplayAttributes\n  nameWithType: DisplayAttributes\n  fullName: System.Speech.Recognition.DisplayAttributes\n- uid: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: EmulateRecognizeCompletedEventArgs\n  nameWithType: EmulateRecognizeCompletedEventArgs\n  fullName: System.Speech.Recognition.EmulateRecognizeCompletedEventArgs\n- uid: System.Speech.Recognition.Grammar\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: Grammar\n  nameWithType: Grammar\n  fullName: System.Speech.Recognition.Grammar\n- uid: System.Speech.Recognition.GrammarBuilder\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: GrammarBuilder\n  nameWithType: GrammarBuilder\n  fullName: System.Speech.Recognition.GrammarBuilder\n- uid: System.Speech.Recognition.LoadGrammarCompletedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: LoadGrammarCompletedEventArgs\n  nameWithType: LoadGrammarCompletedEventArgs\n  fullName: System.Speech.Recognition.LoadGrammarCompletedEventArgs\n- uid: System.Speech.Recognition.RecognitionEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognitionEventArgs\n  nameWithType: RecognitionEventArgs\n  fullName: System.Speech.Recognition.RecognitionEventArgs\n- uid: System.Speech.Recognition.RecognitionResult\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognitionResult\n  nameWithType: RecognitionResult\n  fullName: System.Speech.Recognition.RecognitionResult\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizeCompletedEventArgs\n  nameWithType: RecognizeCompletedEventArgs\n  fullName: System.Speech.Recognition.RecognizeCompletedEventArgs\n- uid: System.Speech.Recognition.RecognizedAudio\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedAudio\n  nameWithType: RecognizedAudio\n  fullName: System.Speech.Recognition.RecognizedAudio\n- uid: System.Speech.Recognition.RecognizedPhrase\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedPhrase\n  nameWithType: RecognizedPhrase\n  fullName: System.Speech.Recognition.RecognizedPhrase\n- uid: System.Speech.Recognition.RecognizedWordUnit\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedWordUnit\n  nameWithType: RecognizedWordUnit\n  fullName: System.Speech.Recognition.RecognizedWordUnit\n- uid: System.Speech.Recognition.RecognizeMode\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizeMode\n  nameWithType: RecognizeMode\n  fullName: System.Speech.Recognition.RecognizeMode\n- uid: System.Speech.Recognition.RecognizerInfo\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizerInfo\n  nameWithType: RecognizerInfo\n  fullName: System.Speech.Recognition.RecognizerInfo\n- uid: System.Speech.Recognition.RecognizerState\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizerState\n  nameWithType: RecognizerState\n  fullName: System.Speech.Recognition.RecognizerState\n- uid: System.Speech.Recognition.RecognizerUpdateReachedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizerUpdateReachedEventArgs\n  nameWithType: RecognizerUpdateReachedEventArgs\n  fullName: System.Speech.Recognition.RecognizerUpdateReachedEventArgs\n- uid: System.Speech.Recognition.ReplacementText\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: ReplacementText\n  nameWithType: ReplacementText\n  fullName: System.Speech.Recognition.ReplacementText\n- uid: System.Speech.Recognition.SemanticResultKey\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SemanticResultKey\n  nameWithType: SemanticResultKey\n  fullName: System.Speech.Recognition.SemanticResultKey\n- uid: System.Speech.Recognition.SemanticResultValue\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SemanticResultValue\n  nameWithType: SemanticResultValue\n  fullName: System.Speech.Recognition.SemanticResultValue\n- uid: System.Speech.Recognition.SemanticValue\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SemanticValue\n  nameWithType: SemanticValue\n  fullName: System.Speech.Recognition.SemanticValue\n- uid: System.Speech.Recognition.SpeechDetectedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechDetectedEventArgs\n  nameWithType: SpeechDetectedEventArgs\n  fullName: System.Speech.Recognition.SpeechDetectedEventArgs\n- uid: System.Speech.Recognition.SpeechHypothesizedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechHypothesizedEventArgs\n  nameWithType: SpeechHypothesizedEventArgs\n  fullName: System.Speech.Recognition.SpeechHypothesizedEventArgs\n- uid: System.Speech.Recognition.SpeechRecognitionEngine\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechRecognitionEngine\n  nameWithType: SpeechRecognitionEngine\n  fullName: System.Speech.Recognition.SpeechRecognitionEngine\n- uid: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechRecognitionRejectedEventArgs\n  nameWithType: SpeechRecognitionRejectedEventArgs\n  fullName: System.Speech.Recognition.SpeechRecognitionRejectedEventArgs\n- uid: System.Speech.Recognition.SpeechRecognizedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechRecognizedEventArgs\n  nameWithType: SpeechRecognizedEventArgs\n  fullName: System.Speech.Recognition.SpeechRecognizedEventArgs\n- uid: System.Speech.Recognition.SpeechRecognizer\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechRecognizer\n  nameWithType: SpeechRecognizer\n  fullName: System.Speech.Recognition.SpeechRecognizer\n- uid: System.Speech.Recognition.SpeechUI\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SpeechUI\n  nameWithType: SpeechUI\n  fullName: System.Speech.Recognition.SpeechUI\n- uid: System.Speech.Recognition.StateChangedEventArgs\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: StateChangedEventArgs\n  nameWithType: StateChangedEventArgs\n  fullName: System.Speech.Recognition.StateChangedEventArgs\n- uid: System.Speech.Recognition.SubsetMatchingMode\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: SubsetMatchingMode\n  nameWithType: SubsetMatchingMode\n  fullName: System.Speech.Recognition.SubsetMatchingMode\n"}