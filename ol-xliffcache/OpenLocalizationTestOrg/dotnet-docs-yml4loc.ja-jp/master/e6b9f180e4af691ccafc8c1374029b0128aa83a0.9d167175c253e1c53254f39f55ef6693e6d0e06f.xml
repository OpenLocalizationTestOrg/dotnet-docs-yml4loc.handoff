{"nodes":[{"content":"Contains detailed information about input that was recognized by instances of <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref>.","nodes":[{"pos":[0,216],"content":"Contains detailed information about input that was recognized by instances of <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> or <ph id=\"ph2\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognizer\"&gt;&lt;/xref&gt;</ph>.","source":"Contains detailed information about input that was recognized by instances of <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref>."}],"pos":[886,1103],"yaml":true},{"content":"This class derives from <xref:System.Speech.Recognition.RecognizedPhrase> and provides detailed information about speech recognition, including the following:  \n  \n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> property references the <xref:System.Speech.Recognition.Grammar> that the recognizer used to identify the speech.  \n  \n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase. For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.  \n  \n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result. The semantic information is a dictionary of the key names and associated semantic data.  \n  \n-   The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains a collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the audio input. See <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> for additional information.  \n  \n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input. Each <xref:System.Speech.Recognition.RecognizedWordUnit> contains display format, lexical format, and pronunciation information for the corresponding word.  \n  \n Certain members of the <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, and <xref:System.Speech.Recognition.Grammar> classes can generate a <xref:System.Speech.Recognition.RecognitionResult>. For more information, see the following methods and events.  \n  \n-   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  \n  \n-   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  \n  \n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  \n  \n-   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.  \n  \n For more information about recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"pos":[0,158],"content":"This class derives from <xref:System.Speech.Recognition.RecognizedPhrase> and provides detailed information about speech recognition, including the following:","nodes":[{"content":"This class derives from <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> and provides detailed information about speech recognition, including the following:","pos":[0,158],"source":"This class derives from <xref:System.Speech.Recognition.RecognizedPhrase> and provides detailed information about speech recognition, including the following:"}]},{"pos":[168,346],"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> property references the <xref:System.Speech.Recognition.Grammar> that the recognizer used to identify the speech.","nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A&gt;</ph> property references the <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> that the recognizer used to identify the speech.","pos":[0,178],"source":"The <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> property references the <xref:System.Speech.Recognition.Grammar> that the recognizer used to identify the speech."}]},{"pos":[356,572],"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase. For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.","nodes":[{"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase. For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.","pos":[0,216],"nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Text%2A&gt;</ph> property contains the normalized text for the phrase.","pos":[0,115],"source":"The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase."},{"content":"For more information about text normalization, see <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.ReplacementText&gt;</ph>.","pos":[116,216],"source":" For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>."}]}]},{"pos":[582,806],"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result. The semantic information is a dictionary of the key names and associated semantic data.","nodes":[{"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result. The semantic information is a dictionary of the key names and associated semantic data.","pos":[0,224],"nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A&gt;</ph> property references the semantic information contained in the result.","pos":[0,136],"source":"The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result."},{"content":"The semantic information is a dictionary of the key names and associated semantic data.","pos":[137,224]}]}]},{"pos":[816,1140],"content":"The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains a collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the audio input. See <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> for additional information.","nodes":[{"content":"The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains a collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the audio input. See <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> for additional information.","pos":[0,324],"nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> property contains a collection of <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> objects that represent other candidate interpretations of the audio input.","pos":[0,227],"source":"The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains a collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the audio input."},{"content":"See <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> for additional information.","pos":[228,324],"source":" See <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> for additional information."}]}]},{"pos":[1150,1521],"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input. Each <xref:System.Speech.Recognition.RecognizedWordUnit> contains display format, lexical format, and pronunciation information for the corresponding word.","nodes":[{"content":"The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input. Each <xref:System.Speech.Recognition.RecognizedWordUnit> contains display format, lexical format, and pronunciation information for the corresponding word.","pos":[0,371],"nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Words%2A&gt;</ph> property contains an ordered collection of <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> objects that represent each recognized word in the input.","pos":[0,215],"source":"The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input."},{"content":"Each <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedWordUnit&gt;</ph> contains display format, lexical format, and pronunciation information for the corresponding word.","pos":[216,371],"source":" Each <xref:System.Speech.Recognition.RecognizedWordUnit> contains display format, lexical format, and pronunciation information for the corresponding word."}]}]},{"pos":[1528,1839],"content":"Certain members of the <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, and <xref:System.Speech.Recognition.Grammar> classes can generate a <xref:System.Speech.Recognition.RecognitionResult>. For more information, see the following methods and events.","nodes":[{"content":"Certain members of the <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, and <xref:System.Speech.Recognition.Grammar> classes can generate a <xref:System.Speech.Recognition.RecognitionResult>. For more information, see the following methods and events.","pos":[0,311],"nodes":[{"content":"Certain members of the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph>, <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph>, and <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> classes can generate a <ph id=\"ph4\">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph>.","pos":[0,251],"source":"Certain members of the <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, and <xref:System.Speech.Recognition.Grammar> classes can generate a <xref:System.Speech.Recognition.RecognitionResult>."},{"content":"For more information, see the following methods and events.","pos":[252,311]}]}]},{"pos":[1849,1938],"content":"Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:","nodes":[{"content":"Methods and events of the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> class:","pos":[0,89],"source":"Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:"}]},{"pos":[1952,2028],"content":"<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>","nodes":[]},{"pos":[2042,2123],"content":"<xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>","nodes":[]},{"pos":[2137,2212],"content":"<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>","nodes":[]},{"pos":[2226,2308],"content":"<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>","nodes":[]},{"pos":[2322,2395],"content":"<xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>","nodes":[]},{"pos":[2405,2487],"content":"Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:","nodes":[{"content":"Methods and events of the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> class:","pos":[0,82],"source":"Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:"}]},{"pos":[2501,2570],"content":"<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>","nodes":[]},{"pos":[2584,2658],"content":"<xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>","nodes":[]},{"pos":[2672,2740],"content":"<xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>","nodes":[]},{"pos":[2754,2829],"content":"<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>","nodes":[]},{"pos":[2843,2909],"content":"<xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>","nodes":[]},{"pos":[2919,3041],"content":"The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.","nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.Grammar.SpeechRecognized&gt;</ph> event of the <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.Grammar&gt;</ph> class.","pos":[0,122],"source":"The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class."}]},{"pos":[3048,3203],"content":"For more information about recognition events, see <bpt id=\"p1\">[</bpt>Using Speech Recognition Events<ept id=\"p1\">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.","source":"For more information about recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."}],"pos":[1114,4360],"yaml":true,"extradata":"MT"},{"content":"Gets the collection of possible matches for input to the speech recognizer.","nodes":[{"pos":[0,75],"content":"Gets the collection of possible matches for input to the speech recognizer.","nodes":[{"content":"Gets the collection of possible matches for input to the speech recognizer.","pos":[0,75]}]}],"pos":[8121,8197],"yaml":true},{"content":"Recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> are ordered by the values of their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> properties. The confidence value of a given phrase indicates the probability that the phrase matches the input. The phrase with the highest confidence value is the phrase that most likely matches the input.  \n  \n Each <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> value should be evaluated individually and without reference to the confidence values of other <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. The properties that the <xref:System.Speech.Recognition.RecognitionResult> inherits from <xref:System.Speech.Recognition.RecognizedPhrase> provide detailed information about the phrase with the highest confidence score.  \n  \n One use for the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> collection is for automated error correction. For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \"Did you say 'Anna'?\" If the user says \"no\", then the application could query the user about any alternates that had a high enough <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> score.  \n  \n For more information about speech recognition and the use of recognition alternates, see [Speech Recognition](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) and [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"pos":[0,382],"content":"Recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> are ordered by the values of their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> properties. The confidence value of a given phrase indicates the probability that the phrase matches the input. The phrase with the highest confidence value is the phrase that most likely matches the input.","nodes":[{"content":"Recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> are ordered by the values of their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> properties. The confidence value of a given phrase indicates the probability that the phrase matches the input. The phrase with the highest confidence value is the phrase that most likely matches the input.","pos":[0,382],"nodes":[{"content":"Recognition <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> are ordered by the values of their <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> properties.","pos":[0,187],"source":"Recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> are ordered by the values of their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> properties."},{"content":"The confidence value of a given phrase indicates the probability that the phrase matches the input.","pos":[188,287]},{"content":"The phrase with the highest confidence value is the phrase that most likely matches the input.","pos":[288,382]}]}]},{"pos":[389,838],"content":"Each <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> value should be evaluated individually and without reference to the confidence values of other <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. The properties that the <xref:System.Speech.Recognition.RecognitionResult> inherits from <xref:System.Speech.Recognition.RecognizedPhrase> provide detailed information about the phrase with the highest confidence score.","nodes":[{"content":"Each <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> value should be evaluated individually and without reference to the confidence values of other <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. The properties that the <xref:System.Speech.Recognition.RecognitionResult> inherits from <xref:System.Speech.Recognition.RecognizedPhrase> provide detailed information about the phrase with the highest confidence score.","pos":[0,449],"nodes":[{"content":"Each <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> value should be evaluated individually and without reference to the confidence values of other <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph>.","pos":[0,229],"source":"Each <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> value should be evaluated individually and without reference to the confidence values of other <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>."},{"content":"The properties that the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> inherits from <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> provide detailed information about the phrase with the highest confidence score.","pos":[230,449],"source":" The properties that the <xref:System.Speech.Recognition.RecognitionResult> inherits from <xref:System.Speech.Recognition.RecognizedPhrase> provide detailed information about the phrase with the highest confidence score."}]}]},{"pos":[845,1347],"content":"One use for the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> collection is for automated error correction. For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \"Did you say 'Anna'?\" If the user says \"no\", then the application could query the user about any alternates that had a high enough <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> score.","nodes":[{"content":"One use for the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> collection is for automated error correction. For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \"Did you say 'Anna'?\" If the user says \"no\", then the application could query the user about any alternates that had a high enough <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> score.","pos":[0,502],"nodes":[{"content":"One use for the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.Alternates%2A&gt;</ph> collection is for automated error correction.","pos":[0,126],"source":"One use for the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> collection is for automated error correction."},{"content":"For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \"Did you say 'Anna'?\" If the user says \"no\", then the application could query the user about any alternates that had a high enough <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A&gt;</ph> score.","pos":[127,502],"source":" For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \"Did you say 'Anna'?\" If the user says \"no\", then the application could query the user about any alternates that had a high enough <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> score."}]}]},{"pos":[1354,1642],"content":"For more information about speech recognition and the use of recognition alternates, see <bpt id=\"p1\">[</bpt>Speech Recognition<ept id=\"p1\">](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919)</ept> and <bpt id=\"p2\">[</bpt>Using Speech Recognition Events<ept id=\"p2\">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.","source":"For more information about speech recognition and the use of recognition alternates, see [Speech Recognition](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) and [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."}],"pos":[8208,9863],"yaml":true,"extradata":"MT"},{"content":"A read-only collection of the recognition alternates.","nodes":[{"pos":[0,53],"content":"A read-only collection of the recognition alternates.","nodes":[{"content":"A read-only collection of the recognition alternates.","pos":[0,53]}]}],"pos":[11690,11744],"yaml":true},{"content":"Gets the audio associated with the recognition result.","nodes":[{"pos":[0,54],"content":"Gets the audio associated with the recognition result.","nodes":[{"content":"Gets the audio associated with the recognition result.","pos":[0,54]}]}],"pos":[12749,12804],"yaml":true},{"content":"To get a section of the audio that is associated with a specific range of words in the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method.","nodes":[{"pos":[0,197],"content":"To get a section of the audio that is associated with a specific range of words in the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method.","nodes":[{"content":"To get a section of the audio that is associated with a specific range of words in the recognition result, use the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A&gt;</ph> method.","pos":[0,197],"source":"To get a section of the audio that is associated with a specific range of words in the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method."}]}],"pos":[12815,13013],"yaml":true,"extradata":"MT"},{"content":"The audio associated with the recognition result or `null` if the recognizer generated the result from a call to the `EmulateRecognize` or `EmulateRecognizeAsync` methods of a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> instance.","nodes":[{"pos":[0,323],"content":"The audio associated with the recognition result or <ph id=\"ph1\">`null`</ph> if the recognizer generated the result from a call to the <ph id=\"ph2\">`EmulateRecognize`</ph> or <ph id=\"ph3\">`EmulateRecognizeAsync`</ph> methods of a <ph id=\"ph4\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> or <ph id=\"ph5\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognizer\"&gt;&lt;/xref&gt;</ph> instance.","source":"The audio associated with the recognition result or `null` if the recognizer generated the result from a call to the `EmulateRecognize` or `EmulateRecognizeAsync` methods of a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> instance."}],"pos":[14980,15304],"yaml":true},{"content":"Gets a section of the audio that is associated with a specific range of words in the recognition result.","nodes":[{"pos":[0,104],"content":"Gets a section of the audio that is associated with a specific range of words in the recognition result.","nodes":[{"content":"Gets a section of the audio that is associated with a specific range of words in the recognition result.","pos":[0,104]}]}],"pos":[16785,16890],"yaml":true},{"content":"To get the complete audio associated with the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.","nodes":[{"pos":[0,143],"content":"To get the complete audio associated with the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.","nodes":[{"content":"To get the complete audio associated with the recognition result, use the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult.Audio%2A&gt;</ph> property.","pos":[0,143],"source":"To get the complete audio associated with the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property."}]}],"pos":[16901,17045],"yaml":true,"extradata":"MT"},{"content":"The first word in the range.","nodes":[{"pos":[0,28],"content":"The first word in the range.","nodes":[{"content":"The first word in the range.","pos":[0,28]}]}],"pos":[19414,19443],"yaml":true},{"content":"The last word in the range.","nodes":[{"pos":[0,27],"content":"The last word in the range.","nodes":[{"content":"The last word in the range.","pos":[0,27]}]}],"pos":[19538,19566],"yaml":true},{"content":"The section of audio associated with the word range.","nodes":[{"pos":[0,52],"content":"The section of audio associated with the word range.","nodes":[{"content":"The section of audio associated with the word range.","pos":[0,52]}]}],"pos":[19651,19704],"yaml":true},{"content":"The recognizer generated the result from a call to `EmulateRecognize` or `EmulateRecognizeAsync` methods of the <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> objects.","nodes":[{"pos":[0,258],"content":"The recognizer generated the result from a call to <ph id=\"ph1\">`EmulateRecognize`</ph> or <ph id=\"ph2\">`EmulateRecognizeAsync`</ph> methods of the <ph id=\"ph3\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognizer\"&gt;&lt;/xref&gt;</ph> or <ph id=\"ph4\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> objects.","source":"The recognizer generated the result from a call to `EmulateRecognize` or `EmulateRecognizeAsync` methods of the <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> objects."}],"pos":[19900,20159],"yaml":true},{"content":"Populates a <xref href=\"System.Runtime.Serialization.SerializationInfo\"></xref> instance with the data needed to serialize the target object.","nodes":[{"pos":[0,141],"content":"Populates a <ph id=\"ph1\">&lt;xref href=\"System.Runtime.Serialization.SerializationInfo\"&gt;&lt;/xref&gt;</ph> instance with the data needed to serialize the target object.","source":"Populates a <xref href=\"System.Runtime.Serialization.SerializationInfo\"></xref> instance with the data needed to serialize the target object."}],"pos":[21703,21845],"yaml":true},{"content":"This member is an explicit interface member implementation. It can be used only when the <xref:System.Speech.Recognition.RecognitionResult> instance is cast to an <xref:System.Runtime.Serialization.ISerializable> interface.","nodes":[{"pos":[0,223],"content":"This member is an explicit interface member implementation. It can be used only when the <xref:System.Speech.Recognition.RecognitionResult> instance is cast to an <xref:System.Runtime.Serialization.ISerializable> interface.","nodes":[{"content":"This member is an explicit interface member implementation. It can be used only when the <xref:System.Speech.Recognition.RecognitionResult> instance is cast to an <xref:System.Runtime.Serialization.ISerializable> interface.","pos":[0,223],"nodes":[{"content":"This member is an explicit interface member implementation.","pos":[0,59]},{"content":"It can be used only when the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> instance is cast to an <ph id=\"ph2\">&lt;xref:System.Runtime.Serialization.ISerializable&gt;</ph> interface.","pos":[60,223],"source":" It can be used only when the <xref:System.Speech.Recognition.RecognitionResult> instance is cast to an <xref:System.Runtime.Serialization.ISerializable> interface."}]}]}],"pos":[21856,22080],"yaml":true,"extradata":"MT"},{"content":"The object to populate with data.","nodes":[{"pos":[0,33],"content":"The object to populate with data.","nodes":[{"content":"The object to populate with data.","pos":[0,33]}]}],"pos":[22355,22389],"yaml":true},{"content":"The destination for the serialization.","nodes":[{"pos":[0,38],"content":"The destination for the serialization.","nodes":[{"content":"The destination for the serialization.","pos":[0,38]}]}],"pos":[22484,22523],"yaml":true}],"content":"### YamlMime:ManagedReference\nitems:\n- uid: System.Speech.Recognition.RecognitionResult\n  commentId: T:System.Speech.Recognition.RecognitionResult\n  id: RecognitionResult\n  children:\n  - System.Speech.Recognition.RecognitionResult.Alternates\n  - System.Speech.Recognition.RecognitionResult.Audio\n  - System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)\n  - System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)\n  langs:\n  - csharp\n  name: RecognitionResult\n  nameWithType: RecognitionResult\n  fullName: System.Speech.Recognition.RecognitionResult\n  type: Class\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Contains detailed information about input that was recognized by instances of <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref>.\n  remarks: \"This class derives from <xref:System.Speech.Recognition.RecognizedPhrase> and provides detailed information about speech recognition, including the following:  \\n  \\n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> property references the <xref:System.Speech.Recognition.Grammar> that the recognizer used to identify the speech.  \\n  \\n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> property contains the normalized text for the phrase. For more information about text normalization, see <xref:System.Speech.Recognition.ReplacementText>.  \\n  \\n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> property references the semantic information contained in the result. The semantic information is a dictionary of the key names and associated semantic data.  \\n  \\n-   The <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> property contains a collection of <xref:System.Speech.Recognition.RecognizedPhrase> objects that represent other candidate interpretations of the audio input. See <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> for additional information.  \\n  \\n-   The <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> property contains an ordered collection of <xref:System.Speech.Recognition.RecognizedWordUnit> objects that represent each recognized word in the input. Each <xref:System.Speech.Recognition.RecognizedWordUnit> contains display format, lexical format, and pronunciation information for the corresponding word.  \\n  \\n Certain members of the <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, and <xref:System.Speech.Recognition.Grammar> classes can generate a <xref:System.Speech.Recognition.RecognitionResult>. For more information, see the following methods and events.  \\n  \\n-   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>  \\n  \\n-   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>  \\n  \\n    -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>  \\n  \\n-   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.  \\n  \\n For more information about recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).\"\n  example:\n  - \"The following example shows a handler for the `SpeechRecognized` event of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> or <xref:System.Speech.Recognition.SpeechRecognizer> object, and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \\n  \\n```csharp  \\n  \\n// Handle the SpeechRecognized event.   \\nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \\n{  \\n  if (e.Result == null) return;  \\n  \\n  // Add event handler code here.  \\n  \\n  // The following code illustrates some of the information available  \\n  // in the recognition result.  \\n  Console.WriteLine(\\\"Grammar({0}), {1}: {2}\\\",  \\n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \\n  \\n  // Display the semantic values in the recognition result.  \\n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \\n  {  \\n    Console.WriteLine(\\\" {0} key: {1}\\\",  \\n      child.Key, child.Value.Value ?? \\\"null\\\");  \\n  }  \\n  Console.WriteLine();  \\n  \\n  // Display information about the words in the recognition result.  \\n  foreach (RecognizedWordUnit word in e.Result.Words)  \\n  {  \\n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \\n    Console.WriteLine(\\\" {0,-10} {1,-10} {2,-10} {3} ({4})\\\",  \\n      word.Text, word.LexicalForm, word.Pronunciation,  \\n      audio.Duration, word.DisplayAttributes);  \\n  }  \\n  \\n  // Display the recognition alternates for the result.  \\n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \\n  {  \\n    Console.WriteLine(\\\" alt({0}) {1}\\\", phrase.Confidence, phrase.Text);  \\n  }  \\n}  \\n```\"\n  syntax:\n    content: 'public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable'\n  inheritance:\n  - System.Object\n  - System.Speech.Recognition.RecognizedPhrase\n  implements:\n  - System.Runtime.Serialization.ISerializable\n  inheritedMembers:\n  - System.Object.Equals(System.Object)\n  - System.Object.Equals(System.Object,System.Object)\n  - System.Object.GetHashCode\n  - System.Object.GetType\n  - System.Object.MemberwiseClone\n  - System.Object.ReferenceEquals(System.Object,System.Object)\n  - System.Object.ToString\n  - System.Speech.Recognition.RecognizedPhrase.Confidence\n  - System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics\n  - System.Speech.Recognition.RecognizedPhrase.Grammar\n  - System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId\n  - System.Speech.Recognition.RecognizedPhrase.Homophones\n  - System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits\n  - System.Speech.Recognition.RecognizedPhrase.Semantics\n  - System.Speech.Recognition.RecognizedPhrase.Text\n  - System.Speech.Recognition.RecognizedPhrase.Words\n  attributes: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognitionResult.Alternates\n  commentId: P:System.Speech.Recognition.RecognitionResult.Alternates\n  id: Alternates\n  parent: System.Speech.Recognition.RecognitionResult\n  langs:\n  - csharp\n  name: Alternates\n  nameWithType: RecognitionResult.Alternates\n  fullName: RecognitionResult.Alternates\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets the collection of possible matches for input to the speech recognizer.\n  remarks: \"Recognition <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> are ordered by the values of their <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> properties. The confidence value of a given phrase indicates the probability that the phrase matches the input. The phrase with the highest confidence value is the phrase that most likely matches the input.  \\n  \\n Each <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> value should be evaluated individually and without reference to the confidence values of other <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>. The properties that the <xref:System.Speech.Recognition.RecognitionResult> inherits from <xref:System.Speech.Recognition.RecognizedPhrase> provide detailed information about the phrase with the highest confidence score.  \\n  \\n One use for the <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> collection is for automated error correction. For example, when designing a directory dialog, an application could prompt the user to check if the application has the correct information from a recognition event, as in, \\\"Did you say 'Anna'?\\\" If the user says \\\"no\\\", then the application could query the user about any alternates that had a high enough <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> score.  \\n  \\n For more information about speech recognition and the use of recognition alternates, see [Speech Recognition](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) and [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).\"\n  example:\n  - \"The following example shows a handler for the `SpeechRecognized` event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \\n  \\n```csharp  \\n  \\n// Handle the SpeechRecognized event.   \\nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \\n{  \\n  if (e.Result == null) return;  \\n  \\n  // Add event handler code here.  \\n  \\n  // The following code illustrates some of the information available  \\n  // in the recognition result.  \\n  Console.WriteLine(\\\"Grammar({0}), {1}: {2}\\\",  \\n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \\n  \\n  // Display the semantic values in the recognition result.  \\n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \\n  {  \\n    Console.WriteLine(\\\" {0} key: {1}\\\",  \\n      child.Key, child.Value.Value ?? \\\"null\\\");  \\n  }  \\n  Console.WriteLine();  \\n  \\n  // Display information about the words in the recognition result.  \\n  foreach (RecognizedWordUnit word in e.Result.Words)  \\n  {  \\n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \\n    Console.WriteLine(\\\" {0,-10} {1,-10} {2,-10} {3} ({4})\\\",  \\n      word.Text, word.LexicalForm, word.Pronunciation,  \\n      audio.Duration, word.DisplayAttributes);  \\n  }  \\n  \\n  // Display the recognition alternates for the result.  \\n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \\n  {  \\n    Console.WriteLine(\\\" alt({0}) {1}\\\", phrase.Confidence, phrase.Text);  \\n  }  \\n}  \\n```\"\n  syntax:\n    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase> Alternates { get; }\n    return:\n      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}\n      description: A read-only collection of the recognition alternates.\n  overload: System.Speech.Recognition.RecognitionResult.Alternates*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognitionResult.Audio\n  commentId: P:System.Speech.Recognition.RecognitionResult.Audio\n  id: Audio\n  parent: System.Speech.Recognition.RecognitionResult\n  langs:\n  - csharp\n  name: Audio\n  nameWithType: RecognitionResult.Audio\n  fullName: RecognitionResult.Audio\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets the audio associated with the recognition result.\n  remarks: To get a section of the audio that is associated with a specific range of words in the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A> method.\n  example:\n  - \"The following example shows a handler for the **SpeechRecognized** event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \\n  \\n```csharp  \\n  \\n// Handle the SpeechRecognized event.   \\nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \\n{  \\n  if (e.Result == null) return;  \\n  \\n  // Add event handler code here.  \\n  \\n  // The following code illustrates some of the information available  \\n  // in the recognition result.  \\n      Console.WriteLine(\\\"Grammar({0}): {1}\\\", e.Result.Grammar.Name, e.Result.Text);  \\n      Console.WriteLine(\\\"Audio for result:\\\");  \\n      Console.WriteLine(\\\"  Start time: \\\"+ e.Result.Audio.StartTime);  \\n      Console.WriteLine(\\\"  Duration: \\\" + e.Result.Audio.Duration);  \\n      Console.WriteLine(\\\"  Format: \\\" + e.Result.Audio.Format.EncodingFormat);  \\n  \\n  // Display the semantic values in the recognition result.  \\n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \\n  {  \\n    Console.WriteLine(\\\" {0} key: {1}\\\",  \\n      child.Key, child.Value.Value ?? \\\"null\\\");  \\n  }  \\n  Console.WriteLine();  \\n  \\n  // Display information about the words in the recognition result.  \\n  foreach (RecognizedWordUnit word in e.Result.Words)  \\n  {  \\n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \\n    Console.WriteLine(\\\" {0,-10} {1,-10} {2,-10} {3} ({4})\\\",  \\n      word.Text, word.LexicalForm, word.Pronunciation,  \\n      audio.Duration, word.DisplayAttributes);  \\n  }  \\n  \\n  // Display the recognition alternates for the result.  \\n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \\n  {  \\n    Console.WriteLine(\\\" alt({0}) {1}\\\", phrase.Confidence, phrase.Text);  \\n  }  \\n}  \\n```\"\n  syntax:\n    content: public System.Speech.Recognition.RecognizedAudio Audio { get; }\n    return:\n      type: System.Speech.Recognition.RecognizedAudio\n      description: The audio associated with the recognition result or `null` if the recognizer generated the result from a call to the `EmulateRecognize` or `EmulateRecognizeAsync` methods of a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> instance.\n  overload: System.Speech.Recognition.RecognitionResult.Audio*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)\n  commentId: M:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)\n  id: GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)\n  parent: System.Speech.Recognition.RecognitionResult\n  langs:\n  - csharp\n  name: GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n  fullName: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n  type: Method\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets a section of the audio that is associated with a specific range of words in the recognition result.\n  remarks: To get the complete audio associated with the recognition result, use the <xref:System.Speech.Recognition.RecognitionResult.Audio%2A> property.\n  example:\n  - \"The following example creates a grammar to accept name input and attaches to it a handler for the `SpeechRecognized` event. The grammar uses a wildcard for the name element of the phrase. The event handler uses the audio from the wildcard to create and play a greeting prompt.  \\n  \\n```csharp  \\n  \\nprivate Grammar CreateNameInputGrammar()  \\n{  \\n  GrammarBuilder wildcardBuilder = new GrammarBuilder();  \\n  wildcardBuilder.AppendWildcard();  \\n  SemanticResultKey nameKey =  \\n    new SemanticResultKey(\\\"Name\\\", wildcardBuilder);  \\n  \\n  GrammarBuilder nameBuilder =  \\n    new GrammarBuilder(\\\"My name is\\\");  \\n  nameBuilder.Append(nameKey);  \\n  \\n  Grammar nameGrammar = new Grammar(nameBuilder);  \\n  nameGrammar.Name = \\\"Name input\\\";  \\n  \\n  nameGrammar.SpeechRecognized +=  \\n    new EventHandler<SpeechRecognizedEventArgs>(  \\n      NameInputHandler);  \\n  \\n  return nameGrammar;  \\n}  \\n  \\n// Handle the SpeechRecognized event for the name grammar.  \\nprivate void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  \\n{  \\n  if (e.Result == null) return;  \\n  \\n  RecognitionResult result = e.Result;  \\n  SemanticValue semantics = e.Result.Semantics;  \\n  \\n  if (semantics.ContainsKey(\\\"Name\\\"))  \\n  {  \\n    RecognizedAudio nameAudio =  \\n      result.GetAudioForWordRange(  \\n        result.Words[3], result.Words[result.Words.Count - 1]);  \\n  \\n    // Save the audio. Create a directory and file as necessary.  \\n    FileInfo fi = new FileInfo(@\\\"C:\\\\temp\\\\temp.wav\\\");  \\n    if (!fi.Directory.Exists)  \\n    {  \\n      fi.Directory.Create();  \\n    }  \\n    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  \\n    nameAudio.WriteToWaveStream(stream);  \\n    stream.Close();  \\n  \\n    // Greet the person using the saved audio.  \\n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \\n    PromptBuilder builder = new PromptBuilder();  \\n    builder.AppendText(\\\"Hello\\\");  \\n    builder.AppendAudio(fi.FullName);  \\n    synthesizer.Speak(builder);  \\n  }  \\n}  \\n```\"\n  syntax:\n    content: public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);\n    parameters:\n    - id: firstWord\n      type: System.Speech.Recognition.RecognizedWordUnit\n      description: The first word in the range.\n    - id: lastWord\n      type: System.Speech.Recognition.RecognizedWordUnit\n      description: The last word in the range.\n    return:\n      type: System.Speech.Recognition.RecognizedAudio\n      description: The section of audio associated with the word range.\n  overload: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*\n  exceptions:\n  - type: System.NullReferenceException\n    commentId: T:System.NullReferenceException\n    description: The recognizer generated the result from a call to `EmulateRecognize` or `EmulateRecognizeAsync` methods of the <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> objects.\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)\n  commentId: M:System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)\n  id: System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)\n  isEii: true\n  parent: System.Speech.Recognition.RecognitionResult\n  langs:\n  - csharp\n  name: ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n  nameWithType: RecognitionResult.ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n  fullName: RecognitionResult.ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n  type: Method\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Populates a <xref href=\"System.Runtime.Serialization.SerializationInfo\"></xref> instance with the data needed to serialize the target object.\n  remarks: This member is an explicit interface member implementation. It can be used only when the <xref:System.Speech.Recognition.RecognitionResult> instance is cast to an <xref:System.Runtime.Serialization.ISerializable> interface.\n  syntax:\n    content: void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);\n    parameters:\n    - id: info\n      type: System.Runtime.Serialization.SerializationInfo\n      description: The object to populate with data.\n    - id: context\n      type: System.Runtime.Serialization.StreamingContext\n      description: The destination for the serialization.\n  overload: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\nreferences:\n- uid: System.Speech.Recognition.RecognizedPhrase\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedPhrase\n  nameWithType: RecognizedPhrase\n  fullName: System.Speech.Recognition.RecognizedPhrase\n- uid: System.NullReferenceException\n  parent: System\n  isExternal: false\n  name: NullReferenceException\n  nameWithType: NullReferenceException\n  fullName: System.NullReferenceException\n- uid: System.Speech.Recognition.RecognitionResult.Alternates\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: Alternates\n  nameWithType: RecognitionResult.Alternates\n  fullName: RecognitionResult.Alternates\n- uid: System.Collections.ObjectModel.ReadOnlyCollection`1\n  name: ReadOnlyCollection<T>\n  nameWithType: ReadOnlyCollection<T>\n  fullName: System.Collections.ObjectModel.ReadOnlyCollection<T>\n- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}\n  parent: System.Collections.ObjectModel\n  isExternal: false\n  name: ReadOnlyCollection<RecognizedPhrase>\n  nameWithType: ReadOnlyCollection<RecognizedPhrase>\n  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>\n  spec.csharp:\n  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1\n    name: ReadOnlyCollection\n    nameWithType: ReadOnlyCollection\n    fullName: System.Collections.ObjectModel.ReadOnlyCollection\n  - name: <\n    nameWithType: <\n    fullName: <\n  - uid: System.Speech.Recognition.RecognizedPhrase\n    name: RecognizedPhrase\n    nameWithType: RecognizedPhrase\n    fullName: System.Speech.Recognition.RecognizedPhrase\n  - name: '>'\n    nameWithType: '>'\n    fullName: '>'\n- uid: System.Speech.Recognition.RecognitionResult.Audio\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: Audio\n  nameWithType: RecognitionResult.Audio\n  fullName: RecognitionResult.Audio\n- uid: System.Speech.Recognition.RecognizedAudio\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedAudio\n  nameWithType: RecognizedAudio\n  fullName: System.Speech.Recognition.RecognizedAudio\n- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n  fullName: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit, RecognizedWordUnit)\n- uid: System.Speech.Recognition.RecognizedWordUnit\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognizedWordUnit\n  nameWithType: RecognizedWordUnit\n  fullName: System.Speech.Recognition.RecognizedWordUnit\n- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n  nameWithType: RecognitionResult.ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n  fullName: RecognitionResult.ISerializable.GetObjectData(SerializationInfo, StreamingContext)\n- uid: System.Runtime.Serialization.SerializationInfo\n  parent: System.Runtime.Serialization\n  isExternal: false\n  name: SerializationInfo\n  nameWithType: SerializationInfo\n  fullName: System.Runtime.Serialization.SerializationInfo\n- uid: System.Runtime.Serialization.StreamingContext\n  parent: System.Runtime.Serialization\n  isExternal: false\n  name: StreamingContext\n  nameWithType: StreamingContext\n  fullName: System.Runtime.Serialization.StreamingContext\n- uid: System.Speech.Recognition.RecognitionResult.Alternates*\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: Alternates\n  nameWithType: RecognitionResult.Alternates\n  fullName: RecognitionResult.Alternates\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n- uid: System.Speech.Recognition.RecognitionResult.Audio*\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: Audio\n  nameWithType: RecognitionResult.Audio\n  fullName: RecognitionResult.Audio\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: GetAudioForWordRange\n  nameWithType: RecognitionResult.GetAudioForWordRange\n  fullName: RecognitionResult.GetAudioForWordRange\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*\n  parent: System.Speech.Recognition.RecognitionResult\n  isExternal: false\n  name: System.Runtime.Serialization.ISerializable.GetObjectData\n  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData\n  fullName: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognitionResult.xml\n- uid: System.Object.Equals(System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object)\n  nameWithType: Object.Equals(Object)\n  fullName: Object.Equals(Object)\n- uid: System.Object.Equals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object, Object)\n  nameWithType: Object.Equals(Object, Object)\n  fullName: Object.Equals(Object, Object)\n- uid: System.Object.GetHashCode\n  parent: System.Object\n  isExternal: false\n  name: GetHashCode()\n  nameWithType: Object.GetHashCode()\n  fullName: Object.GetHashCode()\n- uid: System.Object.GetType\n  parent: System.Object\n  isExternal: false\n  name: GetType()\n  nameWithType: Object.GetType()\n  fullName: Object.GetType()\n- uid: System.Object.MemberwiseClone\n  parent: System.Object\n  isExternal: false\n  name: MemberwiseClone()\n  nameWithType: Object.MemberwiseClone()\n  fullName: Object.MemberwiseClone()\n- uid: System.Object.ReferenceEquals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: ReferenceEquals(Object, Object)\n  nameWithType: Object.ReferenceEquals(Object, Object)\n  fullName: Object.ReferenceEquals(Object, Object)\n- uid: System.Object.ToString\n  parent: System.Object\n  isExternal: false\n  name: ToString()\n  nameWithType: Object.ToString()\n  fullName: Object.ToString()\n- uid: System.Speech.Recognition.RecognizedPhrase.Confidence\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Confidence\n  nameWithType: RecognizedPhrase.Confidence\n  fullName: RecognizedPhrase.Confidence\n- uid: System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: ConstructSmlFromSemantics()\n  nameWithType: RecognizedPhrase.ConstructSmlFromSemantics()\n  fullName: RecognizedPhrase.ConstructSmlFromSemantics()\n- uid: System.Speech.Recognition.RecognizedPhrase.Grammar\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Grammar\n  nameWithType: RecognizedPhrase.Grammar\n  fullName: RecognizedPhrase.Grammar\n- uid: System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: HomophoneGroupId\n  nameWithType: RecognizedPhrase.HomophoneGroupId\n  fullName: RecognizedPhrase.HomophoneGroupId\n- uid: System.Speech.Recognition.RecognizedPhrase.Homophones\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Homophones\n  nameWithType: RecognizedPhrase.Homophones\n  fullName: RecognizedPhrase.Homophones\n- uid: System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: ReplacementWordUnits\n  nameWithType: RecognizedPhrase.ReplacementWordUnits\n  fullName: RecognizedPhrase.ReplacementWordUnits\n- uid: System.Speech.Recognition.RecognizedPhrase.Semantics\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Semantics\n  nameWithType: RecognizedPhrase.Semantics\n  fullName: RecognizedPhrase.Semantics\n- uid: System.Speech.Recognition.RecognizedPhrase.Text\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Text\n  nameWithType: RecognizedPhrase.Text\n  fullName: RecognizedPhrase.Text\n- uid: System.Speech.Recognition.RecognizedPhrase.Words\n  parent: System.Speech.Recognition.RecognizedPhrase\n  isExternal: false\n  name: Words\n  nameWithType: RecognizedPhrase.Words\n  fullName: RecognizedPhrase.Words\n- uid: System.Runtime.Serialization.ISerializable\n  parent: System.Runtime.Serialization\n  isExternal: false\n  name: ISerializable\n  nameWithType: ISerializable\n  fullName: System.Runtime.Serialization.ISerializable\n"}