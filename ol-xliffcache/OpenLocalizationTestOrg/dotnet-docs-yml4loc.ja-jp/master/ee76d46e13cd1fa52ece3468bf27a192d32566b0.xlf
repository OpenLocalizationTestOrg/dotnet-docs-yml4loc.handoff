<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="ja-jp">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-fdd610b" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ee76d46e13cd1fa52ece3468bf27a192d32566b0</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">System.Speech.Synthesis.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">net47</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">82e8f61f0bc3544184fcbdb0b693488c6bf95155</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">341d2b07b13322ef20da253b60d2711406be6350</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>The <bpt id="p1">&lt;code&gt;</bpt><ph id="ph1">N:System.Speech.Synthesis</ph><ept id="p1">&lt;/code&gt;</ept> namespace contains classes for initializing and configuring a speech synthesis engine, for creating prompts, for generating speech, for responding to events, and for modifying voice characteristics.</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Initialize and Configure<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> class provides access to the functionality of a speech synthesis engine that is installed on the host computer.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>Installed speech synthesis engines are represented by a voice, for example Microsoft Anna.</source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source>A <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> instance initializes to the default voice.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>To configure a <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> instance to use one of the other installed voices, call the <ph id="ph2">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoice%2A&gt;</ph> or <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about which voices are installed, use the <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.GetInstalledVoices%2A&gt;</ph> method.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can route the output of the <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> to a stream, a file, the default audio device, or to a null device by using one of the methods in the <ph id="ph2">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> class whose name begins with "<ph id="ph3">`SetOutputTo`</ph>".</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Create Prompts<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>Use one the methods of the <ph id="ph1">&lt;xref:System.Speech.Synthesis.PromptBuilder&gt;</ph> class whose name begins with "<ph id="ph2">`Append`</ph>" to build content for prompts from text, Speech Synthesis Markup Language (SSML), files containing text or SSML markup, or prerecorded audio files.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Constructing a Complex Prompt<ept id="p1">](http://msdn.microsoft.com/en-us/552cb356-7344-473e-b0f2-7a9983f8c1a4)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Generate Speech<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>To generate speech from a string or from a <ph id="ph1">&lt;xref:System.Speech.Synthesis.Prompt&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Synthesis.PromptBuilder&gt;</ph> object, use the <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.Speak%2A&gt;</ph> or the <ph id="ph4">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakAsync%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>To generate speech from SSML markup, use the <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsml%2A&gt;</ph> or the <ph id="ph2">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SpeakSsmlAsync%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Speech Synthesis Markup Language Reference<ept id="p1">](http://msdn.microsoft.com/en-us/0c51279e-84d2-4f73-a924-8832039abf94)</ept> for a guide to SSML markup.</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can guide the pronunciation of words by using the <ph id="ph1">&lt;xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithHint%2A&gt;</ph> or <ph id="ph2">&lt;xref:System.Speech.Synthesis.PromptBuilder.AppendTextWithPronunciation%2A&gt;</ph> methods, and by adding or removing lexicons for a <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> instance using the <ph id="ph4">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.AddLexicon%2A&gt;</ph> and <ph id="ph5">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.RemoveLexicon%2A&gt;</ph> methods.</source>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Respond to Events<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> class includes events that inform a speech application that the <ph id="ph2">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> encountered a specific feature in a prompt, as reported by the <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeakProgressEventArgs&gt;</ph>, <ph id="ph4">&lt;xref:System.Speech.Synthesis.BookmarkReachedEventArgs&gt;</ph>, <ph id="ph5">&lt;xref:System.Speech.Synthesis.PhonemeReachedEventArgs&gt;</ph>, and <ph id="ph6">&lt;xref:System.Speech.Synthesis.VisemeReachedEventArgs&gt;</ph> classes.</source>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve" extradata="MT">
          <source>To get information about the beginning and end of the speaking of a prompt by the <ph id="ph1">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph>, use the <ph id="ph2">&lt;xref:System.Speech.Synthesis.SpeakStartedEventArgs&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeakCompletedEventArgs&gt;</ph> classes.</source>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Using Speech Synthesis Events<ept id="p1">](http://msdn.microsoft.com/en-us/09bf41e6-b88c-4ff2-9287-e42bfd38d836)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information and examples.</source>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve" extradata="MT">
          <source><bpt id="p1">**</bpt>Modify Voice Characteristics<ept id="p1">**</ept></source>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <ph id="ph1">&lt;xref:System.Speech.Synthesis.PromptStyle&gt;</ph> class and <ph id="ph2">&lt;xref:System.Speech.Synthesis.PromptBuilder.StartStyle%2A&gt;</ph> and <ph id="ph3">&lt;xref:System.Speech.Synthesis.PromptBuilder.AppendText%2A&gt;</ph> methods let you modify characteristics of a <ph id="ph4">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> voice using <ph id="ph5">&lt;xref:System.Speech.Synthesis.PromptStyle.Emphasis%2A&gt;</ph>, <ph id="ph6">&lt;xref:System.Speech.Synthesis.PromptStyle.Rate%2A&gt;</ph>, and <ph id="ph7">&lt;xref:System.Speech.Synthesis.PromptStyle.Volume%2A&gt;</ph> parameters.</source>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve" extradata="MT">
          <source>To modify characteristics of a voice such as culture, age, and gender, use one of the <ph id="ph1">&lt;xref:System.Speech.Synthesis.PromptBuilder.StartVoice%2A&gt;</ph> methods of the <ph id="ph2">&lt;xref:System.Speech.Synthesis.PromptBuilder&gt;</ph> class or the <ph id="ph3">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer.SelectVoiceByHints%2A&gt;</ph> methods of the <ph id="ph4">&lt;xref:System.Speech.Synthesis.SpeechSynthesizer&gt;</ph> class.</source>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve" extradata="MT">
          <source>See <bpt id="p1">[</bpt>Controlling Voice Attributes<ept id="p1">](http://msdn.microsoft.com/en-us/0fa3f10d-2696-4701-9735-68c59ffe4816)</ept> in the <bpt id="p2">[</bpt>System Speech Programming Guide for .NET Framework 4.0<ept id="p2">](http://msdn.microsoft.com/en-us/610116c7-3817-40ff-857b-5d41e8511043)</ept> for more information.</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>