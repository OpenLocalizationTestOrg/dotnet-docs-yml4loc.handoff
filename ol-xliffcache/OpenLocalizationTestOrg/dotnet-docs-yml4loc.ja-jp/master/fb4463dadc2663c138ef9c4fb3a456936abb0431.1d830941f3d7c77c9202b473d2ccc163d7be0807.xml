{"nodes":[{"content":"Provides data for the `RecognizeCompleted` event raised by a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> object.","nodes":[{"pos":[0,208],"content":"Provides data for the <ph id=\"ph1\">`RecognizeCompleted`</ph> event raised by a <ph id=\"ph2\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> or a <ph id=\"ph3\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognizer\"&gt;&lt;/xref&gt;</ph> object.","source":"Provides data for the `RecognizeCompleted` event raised by a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> object."}],"pos":[838,1047],"yaml":true},{"content":"An instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> is created when the <xref:System.Speech.Recognition.SpeechRecognitionEngine> or the <xref:System.Speech.Recognition.SpeechRecognizer> object raises its `SpeechRecognized` event after completing a `RecognizeAsync` operation. For more information about speech recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"pos":[0,477],"content":"An instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> is created when the <xref:System.Speech.Recognition.SpeechRecognitionEngine> or the <xref:System.Speech.Recognition.SpeechRecognizer> object raises its `SpeechRecognized` event after completing a `RecognizeAsync` operation. For more information about speech recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"content":"An instance of <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted&gt;</ph> is created when the <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> or the <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> object raises its <ph id=\"ph4\">`SpeechRecognized`</ph> event after completing a <ph id=\"ph5\">`RecognizeAsync`</ph> operation.","pos":[0,314],"source":"An instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> is created when the <xref:System.Speech.Recognition.SpeechRecognitionEngine> or the <xref:System.Speech.Recognition.SpeechRecognizer> object raises its `SpeechRecognized` event after completing a `RecognizeAsync` operation."},{"content":"For more information about speech recognition events, see <bpt id=\"p1\">[</bpt>Using Speech Recognition Events<ept id=\"p1\">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.","pos":[315,477],"source":" For more information about speech recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."}]}],"pos":[1058,1536],"yaml":true,"extradata":"MT"},{"content":"Gets the location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.","nodes":[{"pos":[0,169],"content":"Gets the location in the input device's audio stream associated with the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"&gt;&lt;/xref&gt;</ph> event.","source":"Gets the location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event."}],"pos":[8067,8237],"yaml":true},{"content":"This property references the position at the beginning of the recognized phrase in the input device's generated audio stream. By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input. These positions can be different. For more information, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"pos":[0,461],"content":"This property references the position at the beginning of the recognized phrase in the input device's generated audio stream. By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input. These positions can be different. For more information, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).","nodes":[{"content":"This property references the position at the beginning of the recognized phrase in the input device's generated audio stream.","pos":[0,125]},{"content":"By contrast, the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A&gt;</ph> property references the recognizer's position within its audio input.","pos":[126,296],"source":" By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input."},{"content":"These positions can be different.","pos":[297,330]},{"content":"For more information, see <bpt id=\"p1\">[</bpt>Using Speech Recognition Events<ept id=\"p1\">](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)</ept>.","pos":[331,461],"source":" For more information, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."}]}],"pos":[8248,8710],"yaml":true,"extradata":"MT"},{"content":"The location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.","nodes":[{"pos":[0,164],"content":"The location in the input device's audio stream associated with the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"&gt;&lt;/xref&gt;</ph> event.","source":"The location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event."}],"pos":[13530,13695],"yaml":true},{"content":"Gets a value that indicates whether a babble timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.","nodes":[{"pos":[0,163],"content":"Gets a value that indicates whether a babble timeout generated the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"&gt;&lt;/xref&gt;</ph> event.","source":"Gets a value that indicates whether a babble timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event."}],"pos":[14821,14985],"yaml":true},{"content":"`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only background noise for longer than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout\"></xref> property; otherwise `false.`","nodes":[{"pos":[0,270],"content":"<ph id=\"ph1\">`true`</ph> if the <ph id=\"ph2\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> has detected only background noise for longer than was specified by its <ph id=\"ph3\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout\"&gt;&lt;/xref&gt;</ph> property; otherwise <ph id=\"ph4\">`false.`</ph>","source":"`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only background noise for longer than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout\"></xref> property; otherwise `false.`"}],"pos":[19814,20087],"yaml":true},{"content":"Gets a value that indicates whether an initial silence timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.","nodes":[{"pos":[0,173],"content":"Gets a value that indicates whether an initial silence timeout generated the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"&gt;&lt;/xref&gt;</ph> event.","source":"Gets a value that indicates whether an initial silence timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event."}],"pos":[21261,21435],"yaml":true},{"content":"`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only silence for a longer time period than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout\"></xref> property; otherwise `false.`","nodes":[{"pos":[0,283],"content":"<ph id=\"ph1\">`true`</ph> if the <ph id=\"ph2\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> has detected only silence for a longer time period than was specified by its <ph id=\"ph3\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout\"&gt;&lt;/xref&gt;</ph> property; otherwise <ph id=\"ph4\">`false.`</ph>","source":"`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only silence for a longer time period than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout\"></xref> property; otherwise `false.`"}],"pos":[26272,26558],"yaml":true},{"content":"Gets a value indicating whether the input stream ended.","nodes":[{"pos":[0,55],"content":"Gets a value indicating whether the input stream ended.","nodes":[{"content":"Gets a value indicating whether the input stream ended.","pos":[0,55]}]}],"pos":[27710,27766],"yaml":true},{"content":"The recognizer sets this property to `true` when a file provides the input stream for the recognizer and the end of the file is reached. The end of the input stream can coincide with a successful recognition operation. For more information about using a file as the input stream, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> methods.","nodes":[{"pos":[0,461],"content":"The recognizer sets this property to `true` when a file provides the input stream for the recognizer and the end of the file is reached. The end of the input stream can coincide with a successful recognition operation. For more information about using a file as the input stream, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> methods.","nodes":[{"content":"The recognizer sets this property to <ph id=\"ph1\">`true`</ph> when a file provides the input stream for the recognizer and the end of the file is reached.","pos":[0,136],"source":"The recognizer sets this property to `true` when a file provides the input stream for the recognizer and the end of the file is reached."},{"content":"The end of the input stream can coincide with a successful recognition operation.","pos":[137,218]},{"content":"For more information about using a file as the input stream, see the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A&gt;</ph> methods.","pos":[219,461],"source":" For more information about using a file as the input stream, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> methods."}]}],"pos":[27777,28239],"yaml":true,"extradata":"MT"},{"content":"`true` if the recognizer no longer has audio input; otherwise, `false`.","nodes":[{"pos":[0,71],"content":"<ph id=\"ph1\">`true`</ph> if the recognizer no longer has audio input; otherwise, <ph id=\"ph2\">`false`</ph>.","source":"`true` if the recognizer no longer has audio input; otherwise, `false`."}],"pos":[33057,33131],"yaml":true},{"content":"Gets the recognition result.","nodes":[{"pos":[0,28],"content":"Gets the recognition result.","nodes":[{"content":"Gets the recognition result.","pos":[0,28]}]}],"pos":[34218,34247],"yaml":true},{"content":"The <xref:System.Speech.Recognition.RecognitionResult> object derives from <xref:System.Speech.Recognition.RecognizedPhrase> and contains full information about a phrase returned by a recognition operation.","nodes":[{"pos":[0,206],"content":"The <xref:System.Speech.Recognition.RecognitionResult> object derives from <xref:System.Speech.Recognition.RecognizedPhrase> and contains full information about a phrase returned by a recognition operation.","nodes":[{"content":"The <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.RecognitionResult&gt;</ph> object derives from <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.RecognizedPhrase&gt;</ph> and contains full information about a phrase returned by a recognition operation.","pos":[0,206],"source":"The <xref:System.Speech.Recognition.RecognitionResult> object derives from <xref:System.Speech.Recognition.RecognizedPhrase> and contains full information about a phrase returned by a recognition operation."}]}],"pos":[34258,34465],"yaml":true,"extradata":"MT"},{"content":"The recognition result if the recognition operation succeeded; otherwise, `null`.","nodes":[{"pos":[0,81],"content":"The recognition result if the recognition operation succeeded; otherwise, <ph id=\"ph1\">`null`</ph>.","source":"The recognition result if the recognition operation succeeded; otherwise, `null`."}],"pos":[39341,39423],"yaml":true}],"content":"### YamlMime:ManagedReference\nitems:\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs\n  commentId: T:System.Speech.Recognition.RecognizeCompletedEventArgs\n  id: RecognizeCompletedEventArgs\n  children:\n  - System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition\n  - System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout\n  - System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout\n  - System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded\n  - System.Speech.Recognition.RecognizeCompletedEventArgs.Result\n  langs:\n  - csharp\n  name: RecognizeCompletedEventArgs\n  nameWithType: RecognizeCompletedEventArgs\n  fullName: System.Speech.Recognition.RecognizeCompletedEventArgs\n  type: Class\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Provides data for the `RecognizeCompleted` event raised by a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> object.\n  remarks: An instance of <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted> is created when the <xref:System.Speech.Recognition.SpeechRecognitionEngine> or the <xref:System.Speech.Recognition.SpeechRecognizer> object raises its `SpeechRecognized` event after completing a `RecognizeAsync` operation. For more information about speech recognition events, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n```\"\n  syntax:\n    content: 'public class RecognizeCompletedEventArgs : System.ComponentModel.AsyncCompletedEventArgs'\n  inheritance:\n  - System.Object\n  - System.EventArgs\n  - System.ComponentModel.AsyncCompletedEventArgs\n  implements: []\n  inheritedMembers:\n  - System.ComponentModel.AsyncCompletedEventArgs.Cancelled\n  - System.ComponentModel.AsyncCompletedEventArgs.Error\n  - System.ComponentModel.AsyncCompletedEventArgs.RaiseExceptionIfNecessary\n  - System.ComponentModel.AsyncCompletedEventArgs.UserState\n  - System.EventArgs.Empty\n  - System.Object.Equals(System.Object)\n  - System.Object.Equals(System.Object,System.Object)\n  - System.Object.GetHashCode\n  - System.Object.GetType\n  - System.Object.MemberwiseClone\n  - System.Object.ReferenceEquals(System.Object,System.Object)\n  - System.Object.ToString\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition\n  commentId: P:System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition\n  id: AudioPosition\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  langs:\n  - csharp\n  name: AudioPosition\n  nameWithType: RecognizeCompletedEventArgs.AudioPosition\n  fullName: RecognizeCompletedEventArgs.AudioPosition\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets the location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.\n  remarks: This property references the position at the beginning of the recognized phrase in the input device's generated audio stream. By contrast, the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizerAudioPosition%2A> property references the recognizer's position within its audio input. These positions can be different. For more information, see [Using Speech Recognition Events](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482).\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n  \\n```\"\n  syntax:\n    content: public TimeSpan AudioPosition { get; }\n    return:\n      type: System.TimeSpan\n      description: The location in the input device's audio stream associated with the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.\n  overload: System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout\n  commentId: P:System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout\n  id: BabbleTimeout\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  langs:\n  - csharp\n  name: BabbleTimeout\n  nameWithType: RecognizeCompletedEventArgs.BabbleTimeout\n  fullName: RecognizeCompletedEventArgs.BabbleTimeout\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets a value that indicates whether a babble timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.\n  remarks: ''\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n  \\n```\"\n  syntax:\n    content: public bool BabbleTimeout { get; }\n    return:\n      type: System.Boolean\n      description: '`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only background noise for longer than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.BabbleTimeout\"></xref> property; otherwise `false.`'\n  overload: System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout\n  commentId: P:System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout\n  id: InitialSilenceTimeout\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  langs:\n  - csharp\n  name: InitialSilenceTimeout\n  nameWithType: RecognizeCompletedEventArgs.InitialSilenceTimeout\n  fullName: RecognizeCompletedEventArgs.InitialSilenceTimeout\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets a value that indicates whether an initial silence timeout generated the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted\"></xref> event.\n  remarks: ''\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n  \\n```\"\n  syntax:\n    content: public bool InitialSilenceTimeout { get; }\n    return:\n      type: System.Boolean\n      description: '`true` if the <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> has detected only silence for a longer time period than was specified by its <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine.InitialSilenceTimeout\"></xref> property; otherwise `false.`'\n  overload: System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded\n  commentId: P:System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded\n  id: InputStreamEnded\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  langs:\n  - csharp\n  name: InputStreamEnded\n  nameWithType: RecognizeCompletedEventArgs.InputStreamEnded\n  fullName: RecognizeCompletedEventArgs.InputStreamEnded\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets a value indicating whether the input stream ended.\n  remarks: The recognizer sets this property to `true` when a file provides the input stream for the recognizer and the end of the file is reached. The end of the input stream can coincide with a successful recognition operation. For more information about using a file as the input stream, see the <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToAudioStream%2A> and <xref:System.Speech.Recognition.SpeechRecognitionEngine.SetInputToWaveFile%2A> methods.\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n  \\n```\"\n  syntax:\n    content: public bool InputStreamEnded { get; }\n    return:\n      type: System.Boolean\n      description: '`true` if the recognizer no longer has audio input; otherwise, `false`.'\n  overload: System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.Result\n  commentId: P:System.Speech.Recognition.RecognizeCompletedEventArgs.Result\n  id: Result\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  langs:\n  - csharp\n  name: Result\n  nameWithType: RecognizeCompletedEventArgs.Result\n  fullName: RecognizeCompletedEventArgs.Result\n  type: Property\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Gets the recognition result.\n  remarks: The <xref:System.Speech.Recognition.RecognitionResult> object derives from <xref:System.Speech.Recognition.RecognizedPhrase> and contains full information about a phrase returned by a recognition operation.\n  example:\n  - \"The following example performs asynchronous speech recognition on a speech recognition grammar, using the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeAsync%2A?displayProperty=fullName> method with the in-process recognizer. The example uses <xref:System.Speech.Recognition.Choices> and <xref:System.Speech.Recognition.GrammarBuilder> objects to create the speech recognition grammar before building it into a <xref:System.Speech.Recognition.Grammar> object. A handler for the <xref:System.Speech.Recognition.SpeechRecognitionEngine.RecognizeCompleted?displayProperty=fullName> event outputs information about the recognition operation to the console.  \\n  \\n```  \\nusing System;  \\nusing System.Speech.Recognition;  \\n  \\nnamespace SampleRecognition  \\n{  \\n  class Program  \\n  {  \\n    private static SpeechRecognitionEngine recognizer;  \\n    public static void Main(string[] args)  \\n    {  \\n  \\n      // Initialize a SpeechRecognitionEngine object and set its input.  \\n      recognizer = new SpeechRecognitionEngine(new System.Globalization.CultureInfo(\\\"en-US\\\"));  \\n      recognizer.SetInputToDefaultAudioDevice();  \\n  \\n      // Configure recognition parameters.  \\n      recognizer.InitialSilenceTimeout = TimeSpan.FromSeconds(5.0);  \\n      recognizer.BabbleTimeout = TimeSpan.FromSeconds(3.0);  \\n      recognizer.EndSilenceTimeout = TimeSpan.FromSeconds(1.0);  \\n      recognizer.EndSilenceTimeoutAmbiguous = TimeSpan.FromSeconds(1.0);  \\n  \\n      // Add a handler for the LoadGrammarCompleted event.  \\n      recognizer.LoadGrammarCompleted +=  \\n        new EventHandler<LoadGrammarCompletedEventArgs>(recognizer_LoadGrammarCompleted);  \\n  \\n      // Add a handler for the RecognizeCompleted event.  \\n      recognizer.RecognizeCompleted +=   \\n        new EventHandler<RecognizeCompletedEventArgs>(recognizer_RecognizeCompleted);  \\n  \\n      // Create a speech recognition grammar and build it into a Grammar object.  \\n      Choices bankingMenu = new Choices(new string[]   \\n      { \\\"Access accounts\\\", \\\"Transfer funds\\\", \\\"Pay bills\\\", \\\"Get loan balance\\\" });  \\n      GrammarBuilder banking = new GrammarBuilder(bankingMenu);  \\n      Grammar bankGrammar = new Grammar(banking);  \\n      bankGrammar.Name = \\\"Banking Menu\\\";  \\n  \\n      // Load the Grammar objects to the recognizer.  \\n      recognizer.LoadGrammarAsync(bankGrammar);  \\n  \\n      // Start asynchronous, continuous recognition.  \\n      recognizer.RecognizeAsync();  \\n  \\n      // Keep the console window open.  \\n      Console.ReadLine();  \\n    }  \\n  \\n    // Handle the RecognizeCompleted event.  \\n    static void recognizer_RecognizeCompleted(object sender, RecognizeCompletedEventArgs e)  \\n    {  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted, error occurred during recognition: {0}\\\", e.Error);  \\n        return;  \\n      }  \\n  \\n      if (e.InitialSilenceTimeout || e.BabbleTimeout)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: BabbleTimeout({0}), InitialSilenceTimeout({1}).\\\",  \\n          e.BabbleTimeout, e.InitialSilenceTimeout);  \\n        return;  \\n      }  \\n  \\n      if (e.InputStreamEnded)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: AudioPosition({0}), InputStreamEnded({1}).\\\",  \\n          e.AudioPosition, e.InputStreamEnded);  \\n      }  \\n  \\n      if (e.Result != null)  \\n      {  \\n        Console.WriteLine(  \\n          \\\"RecognizeCompleted: Grammar ({0}), Text ({1}), Confidence ({2}), AudioPosition ({3}).\\\",  \\n          e.Result.Grammar.Name, e.Result.Text, e.Result.Confidence, e.AudioPosition);  \\n      }  \\n  \\n      else  \\n      {  \\n        Console.WriteLine(\\\"RecognizeCompleted: No result.\\\");  \\n      }   \\n  \\n      Console.WriteLine();  \\n      Console.WriteLine(\\\"Press any key to exit...\\\");  \\n      Console.ReadKey();  \\n    }  \\n  \\n    // Handle the LoadGrammarCompleted event.   \\n    static void recognizer_LoadGrammarCompleted(object sender, LoadGrammarCompletedEventArgs e)  \\n    {  \\n      string grammarName = e.Grammar.Name;  \\n      bool grammarLoaded = e.Grammar.Loaded;  \\n      bool grammarEnabled = e.Grammar.Enabled;  \\n  \\n      if (e.Error != null)  \\n      {  \\n        Console.WriteLine(\\\"LoadGrammar for {0} failed with a {1}.\\\",  \\n        grammarName, e.Error.GetType().Name);  \\n  \\n        // Add exception handling code here.  \\n      }  \\n  \\n      Console.WriteLine(\\\"Grammar {0} {1} loaded and {2} enabled.\\\", grammarName,   \\n        (grammarLoaded) ? \\\"is\\\" : \\\"is not\\\", (grammarEnabled) ? \\\"is\\\" : \\\"is not\\\");  \\n    }  \\n  }            \\n}  \\n  \\n```\"\n  syntax:\n    content: public System.Speech.Recognition.RecognitionResult Result { get; }\n    return:\n      type: System.Speech.Recognition.RecognitionResult\n      description: The recognition result if the recognition operation succeeded; otherwise, `null`.\n  overload: System.Speech.Recognition.RecognizeCompletedEventArgs.Result*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\nreferences:\n- uid: System.ComponentModel.AsyncCompletedEventArgs\n  parent: System.ComponentModel\n  isExternal: false\n  name: AsyncCompletedEventArgs\n  nameWithType: AsyncCompletedEventArgs\n  fullName: System.ComponentModel.AsyncCompletedEventArgs\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: AudioPosition\n  nameWithType: RecognizeCompletedEventArgs.AudioPosition\n  fullName: RecognizeCompletedEventArgs.AudioPosition\n- uid: System.TimeSpan\n  parent: System\n  isExternal: false\n  name: TimeSpan\n  nameWithType: TimeSpan\n  fullName: System.TimeSpan\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: BabbleTimeout\n  nameWithType: RecognizeCompletedEventArgs.BabbleTimeout\n  fullName: RecognizeCompletedEventArgs.BabbleTimeout\n- uid: System.Boolean\n  parent: System\n  isExternal: false\n  name: Boolean\n  nameWithType: Boolean\n  fullName: System.Boolean\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: InitialSilenceTimeout\n  nameWithType: RecognizeCompletedEventArgs.InitialSilenceTimeout\n  fullName: RecognizeCompletedEventArgs.InitialSilenceTimeout\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: InputStreamEnded\n  nameWithType: RecognizeCompletedEventArgs.InputStreamEnded\n  fullName: RecognizeCompletedEventArgs.InputStreamEnded\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.Result\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: Result\n  nameWithType: RecognizeCompletedEventArgs.Result\n  fullName: RecognizeCompletedEventArgs.Result\n- uid: System.Speech.Recognition.RecognitionResult\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: RecognitionResult\n  nameWithType: RecognitionResult\n  fullName: System.Speech.Recognition.RecognitionResult\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.AudioPosition*\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: AudioPosition\n  nameWithType: RecognizeCompletedEventArgs.AudioPosition\n  fullName: RecognizeCompletedEventArgs.AudioPosition\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.BabbleTimeout*\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: BabbleTimeout\n  nameWithType: RecognizeCompletedEventArgs.BabbleTimeout\n  fullName: RecognizeCompletedEventArgs.BabbleTimeout\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InitialSilenceTimeout*\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: InitialSilenceTimeout\n  nameWithType: RecognizeCompletedEventArgs.InitialSilenceTimeout\n  fullName: RecognizeCompletedEventArgs.InitialSilenceTimeout\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.InputStreamEnded*\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: InputStreamEnded\n  nameWithType: RecognizeCompletedEventArgs.InputStreamEnded\n  fullName: RecognizeCompletedEventArgs.InputStreamEnded\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n- uid: System.Speech.Recognition.RecognizeCompletedEventArgs.Result*\n  parent: System.Speech.Recognition.RecognizeCompletedEventArgs\n  isExternal: false\n  name: Result\n  nameWithType: RecognizeCompletedEventArgs.Result\n  fullName: RecognizeCompletedEventArgs.Result\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/RecognizeCompletedEventArgs.xml\n- uid: System.Object.Equals(System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object)\n  nameWithType: Object.Equals(Object)\n  fullName: Object.Equals(Object)\n- uid: System.Object.Equals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object, Object)\n  nameWithType: Object.Equals(Object, Object)\n  fullName: Object.Equals(Object, Object)\n- uid: System.Object.GetHashCode\n  parent: System.Object\n  isExternal: false\n  name: GetHashCode()\n  nameWithType: Object.GetHashCode()\n  fullName: Object.GetHashCode()\n- uid: System.Object.GetType\n  parent: System.Object\n  isExternal: false\n  name: GetType()\n  nameWithType: Object.GetType()\n  fullName: Object.GetType()\n- uid: System.Object.MemberwiseClone\n  parent: System.Object\n  isExternal: false\n  name: MemberwiseClone()\n  nameWithType: Object.MemberwiseClone()\n  fullName: Object.MemberwiseClone()\n- uid: System.Object.ReferenceEquals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: ReferenceEquals(Object, Object)\n  nameWithType: Object.ReferenceEquals(Object, Object)\n  fullName: Object.ReferenceEquals(Object, Object)\n- uid: System.Object.ToString\n  parent: System.Object\n  isExternal: false\n  name: ToString()\n  nameWithType: Object.ToString()\n  fullName: Object.ToString()\n- uid: System.EventArgs.Empty\n  parent: System.EventArgs\n  isExternal: false\n  name: Empty\n  nameWithType: EventArgs.Empty\n  fullName: EventArgs.Empty\n- uid: System.ComponentModel.AsyncCompletedEventArgs.Cancelled\n  parent: System.ComponentModel.AsyncCompletedEventArgs\n  isExternal: false\n  name: Cancelled\n  nameWithType: AsyncCompletedEventArgs.Cancelled\n  fullName: AsyncCompletedEventArgs.Cancelled\n- uid: System.ComponentModel.AsyncCompletedEventArgs.Error\n  parent: System.ComponentModel.AsyncCompletedEventArgs\n  isExternal: false\n  name: Error\n  nameWithType: AsyncCompletedEventArgs.Error\n  fullName: AsyncCompletedEventArgs.Error\n- uid: System.ComponentModel.AsyncCompletedEventArgs.RaiseExceptionIfNecessary\n  parent: System.ComponentModel.AsyncCompletedEventArgs\n  isExternal: false\n  name: RaiseExceptionIfNecessary()\n  nameWithType: AsyncCompletedEventArgs.RaiseExceptionIfNecessary()\n  fullName: AsyncCompletedEventArgs.RaiseExceptionIfNecessary()\n- uid: System.ComponentModel.AsyncCompletedEventArgs.UserState\n  parent: System.ComponentModel.AsyncCompletedEventArgs\n  isExternal: false\n  name: UserState\n  nameWithType: AsyncCompletedEventArgs.UserState\n  fullName: AsyncCompletedEventArgs.UserState\n"}