{"nodes":[{"content":"Represents a speech recognition grammar used for free text dictation.","nodes":[{"pos":[0,69],"content":"Represents a speech recognition grammar used for free text dictation.","nodes":[{"content":"Represents a speech recognition grammar used for free text dictation.","pos":[0,69]}]}],"pos":[625,695],"yaml":true},{"content":"This class provides applications with a predefined language model that can process spoken user input into text. This class supports both default and custom <xref:System.Speech.Recognition.DictationGrammar> objects. For information about selecting a dictation grammar, see the <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor.  \n  \n By default, the <xref:System.Speech.Recognition.DictationGrammar> language model is context free. It does not make use of specific words or word order to identify and interpret audio input. To add context to the dictation grammar, use the <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method.  \n  \n> [!NOTE]\n>  <xref:System.Speech.Recognition.DictationGrammar> objects do not support the <xref:System.Speech.Recognition.Grammar.Priority%2A> property. <xref:System.Speech.Recognition.DictationGrammar> throws a <xref:System.NotSupportedException> if <xref:System.Speech.Recognition.Grammar.Priority%2A> is set.","nodes":[{"pos":[0,365],"content":"This class provides applications with a predefined language model that can process spoken user input into text. This class supports both default and custom <xref:System.Speech.Recognition.DictationGrammar> objects. For information about selecting a dictation grammar, see the <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor.","nodes":[{"content":"This class provides applications with a predefined language model that can process spoken user input into text. This class supports both default and custom <xref:System.Speech.Recognition.DictationGrammar> objects. For information about selecting a dictation grammar, see the <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor.","pos":[0,365],"nodes":[{"content":"This class provides applications with a predefined language model that can process spoken user input into text.","pos":[0,111]},{"content":"This class supports both default and custom <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> objects.","pos":[112,214],"source":" This class supports both default and custom <xref:System.Speech.Recognition.DictationGrammar> objects."},{"content":"For information about selecting a dictation grammar, see the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29&gt;</ph> constructor.","pos":[215,365],"source":" For information about selecting a dictation grammar, see the <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor."}]}]},{"pos":[372,691],"content":"By default, the <xref:System.Speech.Recognition.DictationGrammar> language model is context free. It does not make use of specific words or word order to identify and interpret audio input. To add context to the dictation grammar, use the <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method.","nodes":[{"content":"By default, the <xref:System.Speech.Recognition.DictationGrammar> language model is context free. It does not make use of specific words or word order to identify and interpret audio input. To add context to the dictation grammar, use the <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method.","pos":[0,319],"nodes":[{"content":"By default, the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> language model is context free.","pos":[0,97],"source":"By default, the <xref:System.Speech.Recognition.DictationGrammar> language model is context free."},{"content":"It does not make use of specific words or word order to identify and interpret audio input.","pos":[98,189]},{"content":"To add context to the dictation grammar, use the <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> method.","pos":[190,319],"source":" To add context to the dictation grammar, use the <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method."}]}]},{"pos":[699,1008],"content":"[!NOTE]\n <xref:System.Speech.Recognition.DictationGrammar> objects do not support the <xref:System.Speech.Recognition.Grammar.Priority%2A> property. <xref:System.Speech.Recognition.DictationGrammar> throws a <xref:System.NotSupportedException> if <xref:System.Speech.Recognition.Grammar.Priority%2A> is set.","leadings":["","> "],"nodes":[{"content":" <xref:System.Speech.Recognition.DictationGrammar> objects do not support the <xref:System.Speech.Recognition.Grammar.Priority%2A> property. <xref:System.Speech.Recognition.DictationGrammar> throws a <xref:System.NotSupportedException> if <xref:System.Speech.Recognition.Grammar.Priority%2A> is set.","pos":[8,307],"nodes":[{"content":"<ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> objects do not support the <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> property.","pos":[1,140],"source":" <xref:System.Speech.Recognition.DictationGrammar> objects do not support the <xref:System.Speech.Recognition.Grammar.Priority%2A> property."},{"content":"<ph id=\"ph1\">&lt;xref:System.Speech.Recognition.DictationGrammar&gt;</ph> throws a <ph id=\"ph2\">&lt;xref:System.NotSupportedException&gt;</ph> if <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.Grammar.Priority%2A&gt;</ph> is set.","pos":[141,299],"source":" <xref:System.Speech.Recognition.DictationGrammar> throws a <xref:System.NotSupportedException> if <xref:System.Speech.Recognition.Grammar.Priority%2A> is set."}]}]}],"pos":[706,1722],"yaml":true,"extradata":"MT"},{"content":"Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class for the default dictation grammar provided by Windows Desktop Speech Technology.","nodes":[{"pos":[0,184],"content":"Initializes a new instance of the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.DictationGrammar\"&gt;&lt;/xref&gt;</ph> class for the default dictation grammar provided by Windows Desktop Speech Technology.","source":"Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class for the default dictation grammar provided by Windows Desktop Speech Technology."}],"pos":[5664,5849],"yaml":true},{"content":"The default dictation grammar emulates standard dictation practices, including punctuation. It does not support the spelling of a word.","nodes":[{"pos":[0,135],"content":"The default dictation grammar emulates standard dictation practices, including punctuation. It does not support the spelling of a word.","nodes":[{"content":"The default dictation grammar emulates standard dictation practices, including punctuation. It does not support the spelling of a word.","pos":[0,135],"nodes":[{"content":"The default dictation grammar emulates standard dictation practices, including punctuation.","pos":[0,91]},{"content":"It does not support the spelling of a word.","pos":[92,135]}]}]}],"pos":[5860,5996],"yaml":true,"extradata":"MT"},{"content":"Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class with a specific dictation grammar.","nodes":[{"pos":[0,138],"content":"Initializes a new instance of the <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.DictationGrammar\"&gt;&lt;/xref&gt;</ph> class with a specific dictation grammar.","source":"Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class with a specific dictation grammar."}],"pos":[7166,7305],"yaml":true},{"content":"The Speech platform uses a specialized URI syntax to define the custom dictation grammar. The value `grammar:dictation` indicates the default dictation grammar. The value `grammar:dictation#spelling` indicates the spelling dictation grammar.","nodes":[{"pos":[0,241],"content":"The Speech platform uses a specialized URI syntax to define the custom dictation grammar. The value `grammar:dictation` indicates the default dictation grammar. The value `grammar:dictation#spelling` indicates the spelling dictation grammar.","nodes":[{"content":"The Speech platform uses a specialized URI syntax to define the custom dictation grammar.","pos":[0,89]},{"content":"The value <ph id=\"ph1\">`grammar:dictation`</ph> indicates the default dictation grammar.","pos":[90,160],"source":" The value `grammar:dictation` indicates the default dictation grammar."},{"content":"The value <ph id=\"ph1\">`grammar:dictation#spelling`</ph> indicates the spelling dictation grammar.","pos":[161,241],"source":" The value `grammar:dictation#spelling` indicates the spelling dictation grammar."}]}],"pos":[7316,7558],"yaml":true,"extradata":"MT"},{"content":"An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <code>grammar:dictation</code> or <code>grammar:dictation#spelling</code>.","nodes":[{"pos":[0,172],"content":"An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <bpt id=\"p1\">&lt;code&gt;</bpt><ph id=\"ph1\">grammar:dictation</ph><ept id=\"p1\">&lt;/code&gt;</ept> or <bpt id=\"p2\">&lt;code&gt;</bpt><ph id=\"ph2\">grammar:dictation#spelling</ph><ept id=\"p2\">&lt;/code&gt;</ept>.","source":"An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <code>grammar:dictation</code> or <code>grammar:dictation#spelling</code>."}],"pos":[7698,7871],"yaml":true},{"content":"Adds a context to a dictation grammar that has been loaded by a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> object.","nodes":[{"pos":[0,211],"content":"Adds a context to a dictation grammar that has been loaded by a <ph id=\"ph1\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognizer\"&gt;&lt;/xref&gt;</ph> or a <ph id=\"ph2\">&lt;xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"&gt;&lt;/xref&gt;</ph> object.","source":"Adds a context to a dictation grammar that has been loaded by a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> object."}],"pos":[9081,9293],"yaml":true},{"content":"By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input. When a context is added to a dictation grammar, the recognition engine uses the `precedingText` and `subsequentText` to identify when to interpret speech as dictation.  \n  \n> [!NOTE]\n>  A dictation grammar must be loaded by a <xref:System.Speech.Recognition.SpeechRecognizer> or <xref:System.Speech.Recognition.SpeechRecognitionEngine> object before you can use <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> to add a context.  \n  \n The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.  \n  \n|`precedingText`|`subsequentText`|Description|  \n|---------------------|----------------------|-----------------|  \n|not `null`|not `null`|The recognition engine uses the terms to bracket possible candidate phrases.|  \n|`null`|not `null`|The recognition engine uses the `subsequentText` to finish dictation.|  \n|not `null`|`null`|The recognition engine uses the `precedingText` to start dictation.|  \n|`null`|`null`|The recognition engine does not use a context when using the dictation grammar.|","nodes":[{"pos":[0,290],"content":"By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input. When a context is added to a dictation grammar, the recognition engine uses the `precedingText` and `subsequentText` to identify when to interpret speech as dictation.","nodes":[{"content":"By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input.","pos":[0,122]},{"content":"When a context is added to a dictation grammar, the recognition engine uses the <ph id=\"ph1\">`precedingText`</ph> and <ph id=\"ph2\">`subsequentText`</ph> to identify when to interpret speech as dictation.","pos":[123,290],"source":" When a context is added to a dictation grammar, the recognition engine uses the `precedingText` and `subsequentText` to identify when to interpret speech as dictation."}]},{"pos":[298,575],"content":"[!NOTE]\n A dictation grammar must be loaded by a <xref:System.Speech.Recognition.SpeechRecognizer> or <xref:System.Speech.Recognition.SpeechRecognitionEngine> object before you can use <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> to add a context.","leadings":["","> "],"nodes":[{"content":"A dictation grammar must be loaded by a <ph id=\"ph1\">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> or <ph id=\"ph2\">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> object before you can use <ph id=\"ph3\">&lt;xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A&gt;</ph> to add a context.","pos":[9,275],"source":" A dictation grammar must be loaded by a <xref:System.Speech.Recognition.SpeechRecognizer> or <xref:System.Speech.Recognition.SpeechRecognitionEngine> object before you can use <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> to add a context."}]},{"pos":[582,710],"content":"The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.","nodes":[{"content":"The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.","pos":[0,128]}]},{"pos":[750,761],"content":"Description","nodes":[{"content":"Description","pos":[0,11]}]},{"pos":[833,843],"content":"not <ph id=\"ph1\">`null`</ph>","source":"not `null`"},{"pos":[844,854],"content":"not <ph id=\"ph1\">`null`</ph>","source":"not `null`"},{"pos":[855,931],"content":"The recognition engine uses the terms to bracket possible candidate phrases.","nodes":[{"content":"The recognition engine uses the terms to bracket possible candidate phrases.","pos":[0,76]}]},{"pos":[943,953],"content":"not <ph id=\"ph1\">`null`</ph>","source":"not `null`"},{"pos":[954,1023],"content":"The recognition engine uses the <ph id=\"ph1\">`subsequentText`</ph> to finish dictation.","source":"The recognition engine uses the `subsequentText` to finish dictation."},{"pos":[1028,1038],"content":"not <ph id=\"ph1\">`null`</ph>","source":"not `null`"},{"pos":[1046,1113],"content":"The recognition engine uses the <ph id=\"ph1\">`precedingText`</ph> to start dictation.","source":"The recognition engine uses the `precedingText` to start dictation."},{"pos":[1132,1211],"content":"The recognition engine does not use a context when using the dictation grammar.","nodes":[{"content":"The recognition engine does not use a context when using the dictation grammar.","pos":[0,79]}]}],"pos":[9304,10531],"yaml":true,"extradata":"MT"},{"content":"Text that indicates the start of a dictation context.","nodes":[{"pos":[0,53],"content":"Text that indicates the start of a dictation context.","nodes":[{"content":"Text that indicates the start of a dictation context.","pos":[0,53]}]}],"pos":[10718,10772],"yaml":true},{"content":"Text that indicates the end of a dictation context.","nodes":[{"pos":[0,51],"content":"Text that indicates the end of a dictation context.","nodes":[{"content":"Text that indicates the end of a dictation context.","pos":[0,51]}]}],"pos":[10842,10894],"yaml":true}],"content":"### YamlMime:ManagedReference\nitems:\n- uid: System.Speech.Recognition.DictationGrammar\n  commentId: T:System.Speech.Recognition.DictationGrammar\n  id: DictationGrammar\n  children:\n  - System.Speech.Recognition.DictationGrammar.#ctor\n  - System.Speech.Recognition.DictationGrammar.#ctor(System.String)\n  - System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)\n  langs:\n  - csharp\n  name: DictationGrammar\n  nameWithType: DictationGrammar\n  fullName: System.Speech.Recognition.DictationGrammar\n  type: Class\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Represents a speech recognition grammar used for free text dictation.\n  remarks: \"This class provides applications with a predefined language model that can process spoken user input into text. This class supports both default and custom <xref:System.Speech.Recognition.DictationGrammar> objects. For information about selecting a dictation grammar, see the <xref:System.Speech.Recognition.DictationGrammar.%23ctor%28System.String%29> constructor.  \\n  \\n By default, the <xref:System.Speech.Recognition.DictationGrammar> language model is context free. It does not make use of specific words or word order to identify and interpret audio input. To add context to the dictation grammar, use the <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method.  \\n  \\n> [!NOTE]\\n>  <xref:System.Speech.Recognition.DictationGrammar> objects do not support the <xref:System.Speech.Recognition.Grammar.Priority%2A> property. <xref:System.Speech.Recognition.DictationGrammar> throws a <xref:System.NotSupportedException> if <xref:System.Speech.Recognition.Grammar.Priority%2A> is set.\"\n  example:\n  - \"The following example creates three dictation grammars, adds them to a new <xref:System.Speech.Recognition.SpeechRecognitionEngine> object, and returns the new object. The first grammar is the default dictation grammar. The second grammar is the spelling dictation grammar. The third grammar is the default dictation grammar that includes a context phrase. The <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> method is used to associate the context phrase with the dictation grammar after it is loaded to the <xref:System.Speech.Recognition.SpeechRecognitionEngine> object.  \\n  \\n```csharp  \\n  \\nprivate SpeechRecognitionEngine LoadDictationGrammars()  \\n{  \\n  \\n  // Create a default dictation grammar.  \\n  DictationGrammar defaultDictationGrammar = new DictationGrammar();  \\n  defaultDictationGrammar.Name = \\\"default dictation\\\";  \\n  defaultDictationGrammar.Enabled = true;  \\n  \\n  // Create the spelling dictation grammar.  \\n  DictationGrammar spellingDictationGrammar =  \\n    new DictationGrammar(\\\"grammar:dictation#spelling\\\");  \\n  spellingDictationGrammar.Name = \\\"spelling dictation\\\";  \\n  spellingDictationGrammar.Enabled = true;  \\n  \\n  // Create the question dictation grammar.  \\n  DictationGrammar customDictationGrammar =  \\n    new DictationGrammar(\\\"grammar:dictation\\\");  \\n  customDictationGrammar.Name = \\\"question dictation\\\";  \\n  customDictationGrammar.Enabled = true;  \\n  \\n  // Create a SpeechRecognitionEngine object and add the grammars to it.  \\n  SpeechRecognitionEngine recoEngine = new SpeechRecognitionEngine();  \\n  recoEngine.LoadGrammar(defaultDictationGrammar);  \\n  recoEngine.LoadGrammar(spellingDictationGrammar);  \\n  recoEngine.LoadGrammar(customDictationGrammar);  \\n  \\n  // Add a context to customDictationGrammar.  \\n  customDictationGrammar.SetDictationContext(\\\"How do you\\\", null);  \\n  \\n  return recoEngine;  \\n}  \\n  \\n```\"\n  syntax:\n    content: 'public class DictationGrammar : System.Speech.Recognition.Grammar'\n  inheritance:\n  - System.Object\n  - System.Speech.Recognition.Grammar\n  implements: []\n  inheritedMembers:\n  - System.Object.Equals(System.Object)\n  - System.Object.Equals(System.Object,System.Object)\n  - System.Object.GetHashCode\n  - System.Object.GetType\n  - System.Object.MemberwiseClone\n  - System.Object.ReferenceEquals(System.Object,System.Object)\n  - System.Object.ToString\n  - System.Speech.Recognition.Grammar.Enabled\n  - System.Speech.Recognition.Grammar.IsStg\n  - System.Speech.Recognition.Grammar.Loaded\n  - System.Speech.Recognition.Grammar.LoadLocalizedGrammarFromType(System.Type,System.Object[])\n  - System.Speech.Recognition.Grammar.Name\n  - System.Speech.Recognition.Grammar.Priority\n  - System.Speech.Recognition.Grammar.ResourceName\n  - System.Speech.Recognition.Grammar.RuleName\n  - System.Speech.Recognition.Grammar.SpeechRecognized\n  - System.Speech.Recognition.Grammar.StgInit(System.Object[])\n  - System.Speech.Recognition.Grammar.Weight\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.DictationGrammar.#ctor\n  commentId: M:System.Speech.Recognition.DictationGrammar.#ctor\n  id: '#ctor'\n  parent: System.Speech.Recognition.DictationGrammar\n  langs:\n  - csharp\n  name: DictationGrammar()\n  nameWithType: DictationGrammar.DictationGrammar()\n  fullName: DictationGrammar.DictationGrammar()\n  type: Constructor\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class for the default dictation grammar provided by Windows Desktop Speech Technology.\n  remarks: The default dictation grammar emulates standard dictation practices, including punctuation. It does not support the spelling of a word.\n  syntax:\n    content: public DictationGrammar ();\n    parameters: []\n  overload: System.Speech.Recognition.DictationGrammar.#ctor*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.DictationGrammar.#ctor(System.String)\n  commentId: M:System.Speech.Recognition.DictationGrammar.#ctor(System.String)\n  id: '#ctor(System.String)'\n  parent: System.Speech.Recognition.DictationGrammar\n  langs:\n  - csharp\n  name: DictationGrammar(String)\n  nameWithType: DictationGrammar.DictationGrammar(String)\n  fullName: DictationGrammar.DictationGrammar(String)\n  type: Constructor\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Initializes a new instance of the <xref href=\"System.Speech.Recognition.DictationGrammar\"></xref> class with a specific dictation grammar.\n  remarks: The Speech platform uses a specialized URI syntax to define the custom dictation grammar. The value `grammar:dictation` indicates the default dictation grammar. The value `grammar:dictation#spelling` indicates the spelling dictation grammar.\n  syntax:\n    content: public DictationGrammar (string topic);\n    parameters:\n    - id: topic\n      type: System.String\n      description: An XML-compliant Universal Resource Identifier (URI) that specifies the dictation grammar, either <code>grammar:dictation</code> or <code>grammar:dictation#spelling</code>.\n  overload: System.Speech.Recognition.DictationGrammar.#ctor*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\n- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)\n  commentId: M:System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)\n  id: SetDictationContext(System.String,System.String)\n  parent: System.Speech.Recognition.DictationGrammar\n  langs:\n  - csharp\n  name: SetDictationContext(String, String)\n  nameWithType: DictationGrammar.SetDictationContext(String, String)\n  fullName: DictationGrammar.SetDictationContext(String, String)\n  type: Method\n  assemblies:\n  - System.Speech\n  namespace: System.Speech.Recognition\n  summary: Adds a context to a dictation grammar that has been loaded by a <xref href=\"System.Speech.Recognition.SpeechRecognizer\"></xref> or a <xref href=\"System.Speech.Recognition.SpeechRecognitionEngine\"></xref> object.\n  remarks: \"By default, the dictation grammar does not make use of specific words or word order to identify and interpret audio input. When a context is added to a dictation grammar, the recognition engine uses the `precedingText` and `subsequentText` to identify when to interpret speech as dictation.  \\n  \\n> [!NOTE]\\n>  A dictation grammar must be loaded by a <xref:System.Speech.Recognition.SpeechRecognizer> or <xref:System.Speech.Recognition.SpeechRecognitionEngine> object before you can use <xref:System.Speech.Recognition.DictationGrammar.SetDictationContext%2A> to add a context.  \\n  \\n The following table describes how the recognition engine uses the two parameters to determine when to use the dictation grammar.  \\n  \\n|`precedingText`|`subsequentText`|Description|  \\n|---------------------|----------------------|-----------------|  \\n|not `null`|not `null`|The recognition engine uses the terms to bracket possible candidate phrases.|  \\n|`null`|not `null`|The recognition engine uses the `subsequentText` to finish dictation.|  \\n|not `null`|`null`|The recognition engine uses the `precedingText` to start dictation.|  \\n|`null`|`null`|The recognition engine does not use a context when using the dictation grammar.|\"\n  syntax:\n    content: public void SetDictationContext (string precedingText, string subsequentText);\n    parameters:\n    - id: precedingText\n      type: System.String\n      description: Text that indicates the start of a dictation context.\n    - id: subsequentText\n      type: System.String\n      description: Text that indicates the end of a dictation context.\n  overload: System.Speech.Recognition.DictationGrammar.SetDictationContext*\n  exceptions: []\n  version:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n  ms.technology:\n  - dotnet-standard\n  ms.author: kbridge\n  manager: ghogen\nreferences:\n- uid: System.Speech.Recognition.Grammar\n  parent: System.Speech.Recognition\n  isExternal: false\n  name: Grammar\n  nameWithType: Grammar\n  fullName: System.Speech.Recognition.Grammar\n- uid: System.Speech.Recognition.DictationGrammar.#ctor\n  parent: System.Speech.Recognition.DictationGrammar\n  isExternal: false\n  name: DictationGrammar()\n  nameWithType: DictationGrammar.DictationGrammar()\n  fullName: DictationGrammar.DictationGrammar()\n- uid: System.Speech.Recognition.DictationGrammar.#ctor(System.String)\n  parent: System.Speech.Recognition.DictationGrammar\n  isExternal: false\n  name: DictationGrammar(String)\n  nameWithType: DictationGrammar.DictationGrammar(String)\n  fullName: DictationGrammar.DictationGrammar(String)\n- uid: System.String\n  parent: System\n  isExternal: false\n  name: String\n  nameWithType: String\n  fullName: System.String\n- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext(System.String,System.String)\n  parent: System.Speech.Recognition.DictationGrammar\n  isExternal: false\n  name: SetDictationContext(String, String)\n  nameWithType: DictationGrammar.SetDictationContext(String, String)\n  fullName: DictationGrammar.SetDictationContext(String, String)\n- uid: System.Speech.Recognition.DictationGrammar.#ctor*\n  parent: System.Speech.Recognition.DictationGrammar\n  isExternal: false\n  name: DictationGrammar\n  nameWithType: DictationGrammar.DictationGrammar\n  fullName: DictationGrammar.DictationGrammar\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n- uid: System.Speech.Recognition.DictationGrammar.SetDictationContext*\n  parent: System.Speech.Recognition.DictationGrammar\n  isExternal: false\n  name: SetDictationContext\n  nameWithType: DictationGrammar.SetDictationContext\n  fullName: DictationGrammar.SetDictationContext\n  monikers:\n  - netframework-4.5.1\n  - netframework-4.5.2\n  - netframework-4.5\n  - netframework-4.6.1\n  - netframework-4.6.2\n  - netframework-4.6\n  - netframework-4.7\n  content_git_url: https://github.com/dotnet/docs/blob/master/xml/System.Speech.Recognition/DictationGrammar.xml\n- uid: System.Object.Equals(System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object)\n  nameWithType: Object.Equals(Object)\n  fullName: Object.Equals(Object)\n- uid: System.Object.Equals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: Equals(Object, Object)\n  nameWithType: Object.Equals(Object, Object)\n  fullName: Object.Equals(Object, Object)\n- uid: System.Object.GetHashCode\n  parent: System.Object\n  isExternal: false\n  name: GetHashCode()\n  nameWithType: Object.GetHashCode()\n  fullName: Object.GetHashCode()\n- uid: System.Object.GetType\n  parent: System.Object\n  isExternal: false\n  name: GetType()\n  nameWithType: Object.GetType()\n  fullName: Object.GetType()\n- uid: System.Object.MemberwiseClone\n  parent: System.Object\n  isExternal: false\n  name: MemberwiseClone()\n  nameWithType: Object.MemberwiseClone()\n  fullName: Object.MemberwiseClone()\n- uid: System.Object.ReferenceEquals(System.Object,System.Object)\n  parent: System.Object\n  isExternal: false\n  name: ReferenceEquals(Object, Object)\n  nameWithType: Object.ReferenceEquals(Object, Object)\n  fullName: Object.ReferenceEquals(Object, Object)\n- uid: System.Object.ToString\n  parent: System.Object\n  isExternal: false\n  name: ToString()\n  nameWithType: Object.ToString()\n  fullName: Object.ToString()\n- uid: System.Speech.Recognition.Grammar.Enabled\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: Enabled\n  nameWithType: Grammar.Enabled\n  fullName: Grammar.Enabled\n- uid: System.Speech.Recognition.Grammar.IsStg\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: IsStg\n  nameWithType: Grammar.IsStg\n  fullName: Grammar.IsStg\n- uid: System.Speech.Recognition.Grammar.Loaded\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: Loaded\n  nameWithType: Grammar.Loaded\n  fullName: Grammar.Loaded\n- uid: System.Speech.Recognition.Grammar.LoadLocalizedGrammarFromType(System.Type,System.Object[])\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: LoadLocalizedGrammarFromType(Type, Object[])\n  nameWithType: Grammar.LoadLocalizedGrammarFromType(Type, Object[])\n  fullName: Grammar.LoadLocalizedGrammarFromType(Type, Object[])\n- uid: System.Speech.Recognition.Grammar.Name\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: Name\n  nameWithType: Grammar.Name\n  fullName: Grammar.Name\n- uid: System.Speech.Recognition.Grammar.Priority\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: Priority\n  nameWithType: Grammar.Priority\n  fullName: Grammar.Priority\n- uid: System.Speech.Recognition.Grammar.ResourceName\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: ResourceName\n  nameWithType: Grammar.ResourceName\n  fullName: Grammar.ResourceName\n- uid: System.Speech.Recognition.Grammar.RuleName\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: RuleName\n  nameWithType: Grammar.RuleName\n  fullName: Grammar.RuleName\n- uid: System.Speech.Recognition.Grammar.SpeechRecognized\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: SpeechRecognized\n  nameWithType: Grammar.SpeechRecognized\n  fullName: Grammar.SpeechRecognized\n- uid: System.Speech.Recognition.Grammar.StgInit(System.Object[])\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: StgInit(Object[])\n  nameWithType: Grammar.StgInit(Object[])\n  fullName: Grammar.StgInit(Object[])\n- uid: System.Speech.Recognition.Grammar.Weight\n  parent: System.Speech.Recognition.Grammar\n  isExternal: false\n  name: Weight\n  nameWithType: Grammar.Weight\n  fullName: Grammar.Weight\n"}