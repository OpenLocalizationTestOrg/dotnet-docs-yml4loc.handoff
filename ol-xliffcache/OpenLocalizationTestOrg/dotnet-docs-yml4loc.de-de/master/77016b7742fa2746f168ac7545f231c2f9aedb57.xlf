<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="markdown" source-language="en-US" target-language="de-de">
    <header>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-fdd610b" tool-company="Microsoft" />
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">77016b7742fa2746f168ac7545f231c2f9aedb57</xliffext:olfilehash>
      <xliffext:olfilepath xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">System.Speech.Recognition.RecognizerState.yml</xliffext:olfilepath>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">net47</xliffext:oltranslationpriority>
      <xliffext:oltranslationtype xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">Human Translation</xliffext:oltranslationtype>
      <xliffext:olskeletonhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">4d029f22458b33a0e56691e7538655cff3917b44</xliffext:olskeletonhash>
      <xliffext:olxliffhash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">f94e539cda35b095124028c9a902c350d1eae4ad</xliffext:olxliffhash>
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>Enumerates values of the recognizer's state.</source>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> encapsulates the running state of the default speech recognition engine for clients using <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> to access the Windows Desktop Speech Recognition Technology service.</source>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve" extradata="MT">
          <source>Applications can obtain the current state of the desktop recognition engine as a <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> object by querying the <ph id="ph2">&lt;xref:System.Speech.Recognition.SpeechRecognizer.State%2A&gt;</ph> property on a <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer&gt;</ph> instance.</source>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve" extradata="MT">
          <source>To obtain the state of the desktop recognition engine after it changes, applications can query the <ph id="ph1">&lt;xref:System.Speech.Recognition.StateChangedEventArgs.RecognizerState%2A&gt;</ph> property of the <ph id="ph2">&lt;xref:System.Speech.Recognition.StateChangedEventArgs&gt;</ph> object passed to a handler for <ph id="ph3">&lt;xref:System.Speech.Recognition.SpeechRecognizer.StateChanged&gt;</ph> events.</source>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> instances run in-process and their running state is under the control of the application.</source>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve" extradata="MT">
          <source>Therefore, <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognitionEngine&gt;</ph> does not contain a property to return a <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> object.</source>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve" extradata="MT">
          <source>The state of a desktop speech recognition server is a read-only property and cannot be controlled programmatically.</source>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve" extradata="MT">
          <source>Users can change a shared speech recognizer's state using the Speech Recognition user interface (UI) or through the <bpt id="p1">**</bpt>Speech Recognition<ept id="p1">**</ept> member of the Windows <bpt id="p2">**</bpt>Control Panel<ept id="p2">**</ept>.</source>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve" extradata="MT">
          <source>Both the <bpt id="p1">**</bpt>On<ept id="p1">**</ept> and <bpt id="p2">**</bpt>Sleep<ept id="p2">**</ept> settings in the Speech Recognition UI correspond to the <ph id="ph1">`Listening`</ph> state.</source>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve" extradata="MT">
          <source>The <bpt id="p1">**</bpt>Off<ept id="p1">**</ept> setting in the Speech Recognition UI corresponds to Stopped.</source>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve" extradata="MT">
          <source><ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> is the other property that affects the readiness of a shared speech recognition engine to receive and process speech input.</source>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve" extradata="MT">
          <source>You can use <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> to control whether or not a shared speech recognition engine's grammars are active for recognition.</source>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve" extradata="MT">
          <source>However, changing the <ph id="ph1">&lt;xref:System.Speech.Recognition.SpeechRecognizer.Enabled%2A&gt;</ph> property has no effect on the <ph id="ph2">&lt;xref:System.Speech.Recognition.RecognizerState&gt;</ph> property.</source>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve" extradata="MT">
          <source>Information such as the description, the supported culture and audio formats, and the recognition engine name is encapsulated in the <ph id="ph1">&lt;xref:System.Speech.Recognition.RecognizerInfo&gt;</ph> type.</source>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>The recognition engine is available to receive and analyze audio input.</source>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>The recognition engine is not receiving or analyzing audio input.</source>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>